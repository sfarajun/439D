{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment Model","provenance":[],"collapsed_sections":["kxL5oVlOj0yG","_BPUojn71Pbi","lLJF0LJ1cl42","6KmduYKb_OGE","g0cs52sdnnvI","aIIKwIH7ttGF","_5_VFBfdAGtU","zNFtaGe_OcBd","w5ECIHgicxSD","j0K4yBPBILNB","FRM1Jrfqntz7"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"kxL5oVlOj0yG"}},{"cell_type":"markdown","source":["## tutorial site: \n","\n","https://towardsdatascience.com/sentiment-analysis-using-lstm-and-glove-embeddings-99223a87fe8e\n","\n","https://towardsdatascience.com/word-embeddings-for-sentiment-analysis-65f42ea5d26e"],"metadata":{"id":"_BPUojn71Pbi"}},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJXWN-MVX38W","executionInfo":{"status":"ok","timestamp":1650837123032,"user_tz":240,"elapsed":709,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"0300dd06-37c7-4b5e-f397-baef0d78c9cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#import necessary libraries\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["data  = pd.read_csv(\"/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/data.csv\")"],"metadata":{"id":"j2p0QDZ1YpJL","executionInfo":{"status":"ok","timestamp":1650837123033,"user_tz":240,"elapsed":6,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":["# Feature Engineeing: Fix Up Data"],"metadata":{"id":"lLJF0LJ1cl42"}},{"cell_type":"markdown","source":["## Setup necessary libraries\n","> the imports and stuff"],"metadata":{"id":"6KmduYKb_OGE"}},{"cell_type":"code","source":["#import all necessary libraries for this tutorial\n","\n","import re\n","import collections\n","\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import stopwords\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils.np_utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from keras import models\n","from keras import layers\n","import keras"],"metadata":{"id":"EjWwnQx51f3F","executionInfo":{"status":"ok","timestamp":1650837124336,"user_tz":240,"elapsed":91,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["data.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"id":"9NeRxCOV305A","executionInfo":{"status":"ok","timestamp":1650837124444,"user_tz":240,"elapsed":11,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"403e0ae3-0569-4ee0-94ab-7680df40eab2"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   no     paper cited_paper  label  \\\n","0   0  A00-1043    A00-2024      0   \n","1   1  H05-1033    A00-2024      0   \n","2   2  I05-2009    A00-2024      0   \n","3   3  I05-2009    A00-2024      0   \n","4   4  I05-2009    A00-2024      0   \n","\n","                                                text  \n","0  We analyzed a set of articles and identified s...  \n","1  Table 3: Example compressions Compression AvgL...  \n","2  5.3 Related works and discussion Our two-step ...  \n","3  (1999) proposed a summarization system based o...  \n","4  We found that the deletion of lead parts did n...  "],"text/html":["\n","  <div id=\"df-52d878f6-4769-4440-9d7b-fe5445de0410\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A00-1043</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>H05-1033</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d878f6-4769-4440-9d7b-fe5445de0410')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-52d878f6-4769-4440-9d7b-fe5445de0410 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-52d878f6-4769-4440-9d7b-fe5445de0410');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","source":["## Removing non-alphabetic characters\n","> remove words and characters that aren't useful from sentences in dataset"],"metadata":{"id":"g0cs52sdnnvI"}},{"cell_type":"code","source":["# define functions to things with no sentiment value (irrelevant words)\n","stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n","             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n","             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n","             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n","             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n","             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n","             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n","             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n","             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n","             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n","             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n","             \n","stopwords = []\n","\n","characters = [\"\"]\n","\n","#function to remove stopwords\n","def remove_stopwords(data):\n","  data['review_without_stopwords'] = data['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n","  return data\n","\n","#function to remove non-alphabetical tags\n","def remove_tags(string):\n","    #result = re.sub('[\\d<.*?:>()-,;|/@!#$%^&*~`_=+]','',string)\n","\n","    pattern = re.compile('[\\W_0-9]+')\n","    dirty_list = string.split()\n","    clean_list = [pattern.sub('', word) for word in dirty_list]\n","    result = ' '.join(clean_list)\n","    \n","    # result = re.sub('[\\W_0-9]+','',string)    #see https://blog.finxter.com/how-to-remove-all-non-alphabet-characters-from-a-string/ for explanation\n","    # result = re.sub('  ',' ',result)\n","    return result"],"metadata":{"id":"4Xfp9GbE6s9l","executionInfo":{"status":"ok","timestamp":1650837124579,"user_tz":240,"elapsed":142,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["clean_dataset[['no', 'paper', 'cited_paper', 'label', 'text', 'w/o stopwords or tags']].iloc[[9, 10, 12]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"id":"qu76dTg2hicA","executionInfo":{"status":"ok","timestamp":1650837124580,"user_tz":240,"elapsed":12,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"d1dfb6b1-8e67-4145-ad77-3ab707ace841"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    no     paper cited_paper  label  \\\n","9    9  J02-4005    A00-2024      1   \n","10  10  J02-4005    A00-2024      0   \n","12  12  J02-4005    A00-2024     -1   \n","\n","                                                 text  \\\n","9   But in fact, the issue of editing in text summ...   \n","10  Jing and McKeown (2000) and Jing (2000) propos...   \n","12  Jing and McKeown (2000) have proposed a rule-b...   \n","\n","                                w/o stopwords or tags  \n","9   But in fact the issue of editing in text summa...  \n","10  Jing and McKeown  and Jing  propose a cutandpa...  \n","12  Jing and McKeown  have proposed a rulebased al...  "],"text/html":["\n","  <div id=\"df-5baef266-baa8-4cc0-bfb8-e9be59972e8b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>w/o stopwords or tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>J02-4005</td>\n","      <td>A00-2024</td>\n","      <td>1</td>\n","      <td>But in fact, the issue of editing in text summ...</td>\n","      <td>But in fact the issue of editing in text summa...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>J02-4005</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>Jing and McKeown (2000) and Jing (2000) propos...</td>\n","      <td>Jing and McKeown  and Jing  propose a cutandpa...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>J02-4005</td>\n","      <td>A00-2024</td>\n","      <td>-1</td>\n","      <td>Jing and McKeown (2000) have proposed a rule-b...</td>\n","      <td>Jing and McKeown  have proposed a rulebased al...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5baef266-baa8-4cc0-bfb8-e9be59972e8b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5baef266-baa8-4cc0-bfb8-e9be59972e8b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5baef266-baa8-4cc0-bfb8-e9be59972e8b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["#remove stopwords\n","clean_dataset = remove_stopwords(data)\n","clean_dataset['w/o stopwords or tags']= clean_dataset['review_without_stopwords'].apply(lambda cw : remove_tags(cw))\n","clean_dataset"],"metadata":{"id":"Tlq-liJ-Gpb9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1650837124732,"user_tz":240,"elapsed":161,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"630998e5-2ff6-49d3-f9b2-437d017b3a96"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      no     paper cited_paper  label  \\\n","0      0  A00-1043    A00-2024      0   \n","1      1  H05-1033    A00-2024      0   \n","2      2  I05-2009    A00-2024      0   \n","3      3  I05-2009    A00-2024      0   \n","4      4  I05-2009    A00-2024      0   \n","..   ...       ...         ...    ...   \n","994  994  N09-1053    J92-4003      0   \n","995  995  P01-1046    J92-4003      0   \n","996  996  P01-1046    J92-4003      0   \n","997  997  P01-1068    J92-4003      0   \n","998  998  P02-1016    J92-4003      0   \n","\n","                                                  text  \\\n","0    We analyzed a set of articles and identified s...   \n","1    Table 3: Example compressions Compression AvgL...   \n","2    5.3 Related works and discussion Our two-step ...   \n","3    (1999) proposed a summarization system based o...   \n","4    We found that the deletion of lead parts did n...   \n","..                                                 ...   \n","994  While we can only compare class models with wo...   \n","995  (1999) and Lee (1999)) can be generally divide...   \n","996  Classes can be induced directly from the corpu...   \n","997  And we consider that word pairs that have a sm...   \n","998  Words are encoded through an automatic cluster...   \n","\n","                              review_without_stopwords  \\\n","0    We analyzed a set of articles and identified s...   \n","1    Table 3: Example compressions Compression AvgL...   \n","2    5.3 Related works and discussion Our two-step ...   \n","3    (1999) proposed a summarization system based o...   \n","4    We found that the deletion of lead parts did n...   \n","..                                                 ...   \n","994  While we can only compare class models with wo...   \n","995  (1999) and Lee (1999)) can be generally divide...   \n","996  Classes can be induced directly from the corpu...   \n","997  And we consider that word pairs that have a sm...   \n","998  Words are encoded through an automatic cluster...   \n","\n","                                 w/o stopwords or tags  \n","0    We analyzed a set of articles and identified s...  \n","1    Table  Example compressions Compression AvgLen...  \n","2     Related works and discussion Our twostep mode...  \n","3     proposed a summarization system based on the ...  \n","4    We found that the deletion of lead parts did n...  \n","..                                                 ...  \n","994  While we can only compare class models with wo...  \n","995   and Lee  can be generally divided into three ...  \n","996  Classes can be induced directly from the corpu...  \n","997  And we consider that word pairs that have a sm...  \n","998  Words are encoded through an automatic cluster...  \n","\n","[999 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-47978ffb-46ff-4693-9db7-f06056454b39\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>review_without_stopwords</th>\n","      <th>w/o stopwords or tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A00-1043</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>H05-1033</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table  Example compressions Compression AvgLen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>Related works and discussion Our twostep mode...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>proposed a summarization system based on the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>994</td>\n","      <td>N09-1053</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>While we can only compare class models with wo...</td>\n","      <td>While we can only compare class models with wo...</td>\n","      <td>While we can only compare class models with wo...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>P01-1046</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>(1999) and Lee (1999)) can be generally divide...</td>\n","      <td>(1999) and Lee (1999)) can be generally divide...</td>\n","      <td>and Lee  can be generally divided into three ...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>P01-1046</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>P01-1068</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>P02-1016</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>999 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47978ffb-46ff-4693-9db7-f06056454b39')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-47978ffb-46ff-4693-9db7-f06056454b39 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-47978ffb-46ff-4693-9db7-f06056454b39');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["clean_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"nnYYCly6BWQA","executionInfo":{"status":"ok","timestamp":1650837124733,"user_tz":240,"elapsed":23,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"8f8f2f1b-b422-4247-a428-5b429c21afbd"},"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      no     paper cited_paper  label  \\\n","0      0  A00-1043    A00-2024      0   \n","1      1  H05-1033    A00-2024      0   \n","2      2  I05-2009    A00-2024      0   \n","3      3  I05-2009    A00-2024      0   \n","4      4  I05-2009    A00-2024      0   \n","..   ...       ...         ...    ...   \n","994  994  N09-1053    J92-4003      0   \n","995  995  P01-1046    J92-4003      0   \n","996  996  P01-1046    J92-4003      0   \n","997  997  P01-1068    J92-4003      0   \n","998  998  P02-1016    J92-4003      0   \n","\n","                                                  text  \\\n","0    We analyzed a set of articles and identified s...   \n","1    Table 3: Example compressions Compression AvgL...   \n","2    5.3 Related works and discussion Our two-step ...   \n","3    (1999) proposed a summarization system based o...   \n","4    We found that the deletion of lead parts did n...   \n","..                                                 ...   \n","994  While we can only compare class models with wo...   \n","995  (1999) and Lee (1999)) can be generally divide...   \n","996  Classes can be induced directly from the corpu...   \n","997  And we consider that word pairs that have a sm...   \n","998  Words are encoded through an automatic cluster...   \n","\n","                              review_without_stopwords  \\\n","0    We analyzed a set of articles and identified s...   \n","1    Table 3: Example compressions Compression AvgL...   \n","2    5.3 Related works and discussion Our two-step ...   \n","3    (1999) proposed a summarization system based o...   \n","4    We found that the deletion of lead parts did n...   \n","..                                                 ...   \n","994  While we can only compare class models with wo...   \n","995  (1999) and Lee (1999)) can be generally divide...   \n","996  Classes can be induced directly from the corpu...   \n","997  And we consider that word pairs that have a sm...   \n","998  Words are encoded through an automatic cluster...   \n","\n","                                 w/o stopwords or tags  \n","0    We analyzed a set of articles and identified s...  \n","1    Table  Example compressions Compression AvgLen...  \n","2     Related works and discussion Our twostep mode...  \n","3     proposed a summarization system based on the ...  \n","4    We found that the deletion of lead parts did n...  \n","..                                                 ...  \n","994  While we can only compare class models with wo...  \n","995   and Lee  can be generally divided into three ...  \n","996  Classes can be induced directly from the corpu...  \n","997  And we consider that word pairs that have a sm...  \n","998  Words are encoded through an automatic cluster...  \n","\n","[999 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-6362609b-01aa-4170-bd13-eacff3f98f19\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>review_without_stopwords</th>\n","      <th>w/o stopwords or tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A00-1043</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>H05-1033</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table  Example compressions Compression AvgLen...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>Related works and discussion Our twostep mode...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>proposed a summarization system based on the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>994</td>\n","      <td>N09-1053</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>While we can only compare class models with wo...</td>\n","      <td>While we can only compare class models with wo...</td>\n","      <td>While we can only compare class models with wo...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>P01-1046</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>(1999) and Lee (1999)) can be generally divide...</td>\n","      <td>(1999) and Lee (1999)) can be generally divide...</td>\n","      <td>and Lee  can be generally divided into three ...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>P01-1046</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","      <td>Classes can be induced directly from the corpu...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>P01-1068</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","      <td>And we consider that word pairs that have a sm...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>P02-1016</td>\n","      <td>J92-4003</td>\n","      <td>0</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","      <td>Words are encoded through an automatic cluster...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>999 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6362609b-01aa-4170-bd13-eacff3f98f19')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6362609b-01aa-4170-bd13-eacff3f98f19 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6362609b-01aa-4170-bd13-eacff3f98f19');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","source":["## Remove data that is too large"],"metadata":{"id":"aIIKwIH7ttGF"}},{"cell_type":"code","source":["# get maxLen for the maximum length of a text \n","maxLen = max(clean_dataset['w/o stopwords or tags'].apply(len))\n","\n","#the row of the maxLen text\n","clean_dataset.loc[clean_dataset['w/o stopwords or tags'].apply(len) == max(clean_dataset['w/o stopwords or tags'].apply(len))]"],"metadata":{"id":"pTcUebCepIyB","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1650837124734,"user_tz":240,"elapsed":22,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"64591a7c-4793-483b-8899-368d6f279c88"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      no     paper cited_paper  label  \\\n","225  225  W99-0505    C94-2113      0   \n","\n","                                                  text  \\\n","225  Towards a Meaning-Full Comparison of Lexieal R...   \n","\n","                              review_without_stopwords  \\\n","225  Towards a Meaning-Full Comparison of Lexieal R...   \n","\n","                                 w/o stopwords or tags  \n","225  Towards a MeaningFull Comparison of Lexieal Re...  "],"text/html":["\n","  <div id=\"df-179e5288-7837-45ef-bed7-f8d9bc9aaf2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>review_without_stopwords</th>\n","      <th>w/o stopwords or tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>225</th>\n","      <td>225</td>\n","      <td>W99-0505</td>\n","      <td>C94-2113</td>\n","      <td>0</td>\n","      <td>Towards a Meaning-Full Comparison of Lexieal R...</td>\n","      <td>Towards a Meaning-Full Comparison of Lexieal R...</td>\n","      <td>Towards a MeaningFull Comparison of Lexieal Re...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-179e5288-7837-45ef-bed7-f8d9bc9aaf2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-179e5288-7837-45ef-bed7-f8d9bc9aaf2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-179e5288-7837-45ef-bed7-f8d9bc9aaf2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["# sizes of texts \n","clean_dataset['w/o stopwords or tags'].apply(len).sort_values()"],"metadata":{"id":"ZvZBe8J2uu0i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650837125021,"user_tz":240,"elapsed":307,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"43d8dff5-a021-45d7-91a6-d4c2976fbc5d"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["144        9\n","127       11\n","36        15\n","205       15\n","393       16\n","       ...  \n","637      902\n","907      969\n","908     1927\n","909     3512\n","225    28696\n","Name: w/o stopwords or tags, Length: 999, dtype: int64"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["#try removing thousand word lines from dataset to make training easier\n","smaller_clean_dataset = clean_dataset.loc[clean_dataset['w/o stopwords or tags'].apply(len) < 1000]\n","smaller_clean_dataset['w/o stopwords or tags'].apply(len).sort_values()"],"metadata":{"id":"IuizTg6gjNf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650837125022,"user_tz":240,"elapsed":13,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"c56062d0-47fb-4bdb-b718-2608655b2f50"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["144      9\n","127     11\n","36      15\n","205     15\n","393     16\n","      ... \n","896    776\n","561    829\n","321    855\n","637    902\n","907    969\n","Name: w/o stopwords or tags, Length: 996, dtype: int64"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["#redefine maxlen as length of new longest sentence\n","maxLen = max(smaller_clean_dataset['w/o stopwords or tags'].apply(len))"],"metadata":{"id":"zTYu-8LfuuN6","executionInfo":{"status":"ok","timestamp":1650837125023,"user_tz":240,"elapsed":12,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":["## One hot encode labels"],"metadata":{"id":"_5_VFBfdAGtU"}},{"cell_type":"code","source":["#copy original dataset as backup if mess up\n","smaller_clean_dataset_orig = smaller_clean_dataset.copy()\n","\n","#add categorical labels for label to original dataset \n","smaller_clean_dataset = pd.concat([smaller_clean_dataset, pd.get_dummies(smaller_clean_dataset['label'], prefix='label_')], axis=1)\n","smaller_clean_dataset.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":594},"id":"qAuJ9ErWC0U7","executionInfo":{"status":"ok","timestamp":1650837125023,"user_tz":240,"elapsed":11,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"981d278f-e2c9-41ef-8b39-ff7d1b16fcae"},"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   no     paper cited_paper  label  \\\n","0   0  A00-1043    A00-2024      0   \n","1   1  H05-1033    A00-2024      0   \n","2   2  I05-2009    A00-2024      0   \n","3   3  I05-2009    A00-2024      0   \n","4   4  I05-2009    A00-2024      0   \n","\n","                                                text  \\\n","0  We analyzed a set of articles and identified s...   \n","1  Table 3: Example compressions Compression AvgL...   \n","2  5.3 Related works and discussion Our two-step ...   \n","3  (1999) proposed a summarization system based o...   \n","4  We found that the deletion of lead parts did n...   \n","\n","                            review_without_stopwords  \\\n","0  We analyzed a set of articles and identified s...   \n","1  Table 3: Example compressions Compression AvgL...   \n","2  5.3 Related works and discussion Our two-step ...   \n","3  (1999) proposed a summarization system based o...   \n","4  We found that the deletion of lead parts did n...   \n","\n","                               w/o stopwords or tags  label__-1  label__0  \\\n","0  We analyzed a set of articles and identified s...          0         1   \n","1  Table  Example compressions Compression AvgLen...          0         1   \n","2   Related works and discussion Our twostep mode...          0         1   \n","3   proposed a summarization system based on the ...          0         1   \n","4  We found that the deletion of lead parts did n...          0         1   \n","\n","   label__1  \n","0         0  \n","1         0  \n","2         0  \n","3         0  \n","4         0  "],"text/html":["\n","  <div id=\"df-ab047be4-2e16-4c5a-a78a-c1d6141b3231\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>review_without_stopwords</th>\n","      <th>w/o stopwords or tags</th>\n","      <th>label__-1</th>\n","      <th>label__0</th>\n","      <th>label__1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>A00-1043</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>We analyzed a set of articles and identified s...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>H05-1033</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table 3: Example compressions Compression AvgL...</td>\n","      <td>Table  Example compressions Compression AvgLen...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>5.3 Related works and discussion Our two-step ...</td>\n","      <td>Related works and discussion Our twostep mode...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>(1999) proposed a summarization system based o...</td>\n","      <td>proposed a summarization system based on the ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I05-2009</td>\n","      <td>A00-2024</td>\n","      <td>0</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>We found that the deletion of lead parts did n...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab047be4-2e16-4c5a-a78a-c1d6141b3231')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab047be4-2e16-4c5a-a78a-c1d6141b3231 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab047be4-2e16-4c5a-a78a-c1d6141b3231');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["smaller_clean_dataset.iloc[:, -3:].to_numpy().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JiQVK-f3HKOm","executionInfo":{"status":"ok","timestamp":1650837125024,"user_tz":240,"elapsed":11,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"0c91768e-da40-4da2-8e4a-5a447c6d7a57"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(996, 3)"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","source":["## Even out dataset by label\n","> Scale up the non-neutral sentiment data\n"],"metadata":{"id":"zNFtaGe_OcBd"}},{"cell_type":"code","source":["#scale up the non-neutral sentiment data\n","print('number of samples per label:')\n","print(smaller_clean_dataset['label'].value_counts())\n","\n","# add all the 1 sentiment data in 11x + first 27 \n","# add all the 1 sentiment data in 42x + first 14\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6z5-VQ8VPGvC","executionInfo":{"status":"ok","timestamp":1650837125221,"user_tz":240,"elapsed":206,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"568905b5-ca59-4037-b087-0e2fed9bdee0"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["number of samples per label:\n"," 0    896\n"," 1     79\n","-1     21\n","Name: label, dtype: int64\n"]}]},{"cell_type":"code","source":["# POSITIVE sentiment data -----\n","#repeat positive sentiment data 10 times\n","vertical_concat = smaller_clean_dataset.loc[smaller_clean_dataset['label'] == 1]\n","for i in range(9):\n","  vertical_concat = pd.concat([vertical_concat, smaller_clean_dataset.loc[smaller_clean_dataset['label'] == 1]], axis=0)\n","\n","#add first 27 entries to that dataset\n","vertical_concat = pd.concat([vertical_concat, vertical_concat.iloc[:27]], axis=0)\n","\n","\n","\n","# NEGATIVE sentiment data -----\n","#repeat positive sentiment data 40 times\n","vertical_concat2 = smaller_clean_dataset.loc[smaller_clean_dataset['label'] == -1]\n","for i in range(40):\n","  vertical_concat2 = pd.concat([vertical_concat2, smaller_clean_dataset.loc[smaller_clean_dataset['label'] == -1]], axis=0)\n","\n","#add first 27 entries to that dataset\n","vertical_concat2 = pd.concat([vertical_concat2, vertical_concat2.iloc[:14]], axis=0)\n","\n","\n","\n","print('new 1 label shape', vertical_concat.shape)\n","print('new -1 label shape', vertical_concat2.shape)\n","vertical_concat.head(3)\n","# vertical_concat2.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"A4ME5mxiSXse","executionInfo":{"status":"ok","timestamp":1650837125221,"user_tz":240,"elapsed":22,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"a022f4d5-1b8b-45e2-a4d4-9ca55f13b4aa"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["new 1 label shape (817, 10)\n","new -1 label shape (875, 10)\n"]},{"output_type":"execute_result","data":{"text/plain":["    no     paper cited_paper  label  \\\n","6    6  I08-2101    A00-2024      1   \n","9    9  J02-4005    A00-2024      1   \n","21  21  W03-1102    A00-2024      1   \n","\n","                                                 text  \\\n","6   al., 1994), compression of sentences with Auto...   \n","9   But in fact, the issue of editing in text summ...   \n","21  The recent approach for editing extracted text...   \n","\n","                             review_without_stopwords  \\\n","6   al., 1994), compression of sentences with Auto...   \n","9   But in fact, the issue of editing in text summ...   \n","21  The recent approach for editing extracted text...   \n","\n","                                w/o stopwords or tags  label__-1  label__0  \\\n","6   al  compression of sentences with Automatic Tr...          0         0   \n","9   But in fact the issue of editing in text summa...          0         0   \n","21  The recent approach for editing extracted text...          0         0   \n","\n","    label__1  \n","6          1  \n","9          1  \n","21         1  "],"text/html":["\n","  <div id=\"df-0da683d5-478d-444a-b054-8882ad761868\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>no</th>\n","      <th>paper</th>\n","      <th>cited_paper</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>review_without_stopwords</th>\n","      <th>w/o stopwords or tags</th>\n","      <th>label__-1</th>\n","      <th>label__0</th>\n","      <th>label__1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>I08-2101</td>\n","      <td>A00-2024</td>\n","      <td>1</td>\n","      <td>al., 1994), compression of sentences with Auto...</td>\n","      <td>al., 1994), compression of sentences with Auto...</td>\n","      <td>al  compression of sentences with Automatic Tr...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>J02-4005</td>\n","      <td>A00-2024</td>\n","      <td>1</td>\n","      <td>But in fact, the issue of editing in text summ...</td>\n","      <td>But in fact, the issue of editing in text summ...</td>\n","      <td>But in fact the issue of editing in text summa...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>21</td>\n","      <td>W03-1102</td>\n","      <td>A00-2024</td>\n","      <td>1</td>\n","      <td>The recent approach for editing extracted text...</td>\n","      <td>The recent approach for editing extracted text...</td>\n","      <td>The recent approach for editing extracted text...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0da683d5-478d-444a-b054-8882ad761868')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0da683d5-478d-444a-b054-8882ad761868 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0da683d5-478d-444a-b054-8882ad761868');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["#save old dataframe \n","old_dataframe = smaller_clean_dataset.copy()\n","\n","#concatenate the dataframes\n","non_neutral_data = pd.concat([vertical_concat, vertical_concat2], axis=0)\n","smaller_clean_dataset = pd.concat([smaller_clean_dataset, non_neutral_data], axis=0)\n","\n","#shuffle data\n","from sklearn.utils import shuffle\n","smaller_clean_dataset = shuffle(smaller_clean_dataset, random_state=0)\n","\n","print('number of samples per label post upscaling:')\n","print(smaller_clean_dataset['label'].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rb4XR5LOWB0z","executionInfo":{"status":"ok","timestamp":1650837125222,"user_tz":240,"elapsed":16,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"03e1cab3-00c5-4c92-ccf4-7aa35e76b457"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["number of samples per label post upscaling:\n","-1    896\n"," 0    896\n"," 1    896\n","Name: label, dtype: int64\n"]}]},{"cell_type":"markdown","source":["# Train and Test Model"],"metadata":{"id":"w5ECIHgicxSD"}},{"cell_type":"markdown","source":["## Train Test split"],"metadata":{"id":"j0K4yBPBILNB"}},{"cell_type":"code","source":["# split into test and training data\n","X_train, X_test,Y_train, Y_test = train_test_split(smaller_clean_dataset['w/o stopwords or tags'], smaller_clean_dataset.iloc[:, -3:].to_numpy(), test_size=0.2, random_state = 45)"],"metadata":{"id":"6kzXRcOQILNC","executionInfo":{"status":"ok","timestamp":1650836028980,"user_tz":240,"elapsed":5,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#Y_train sentiment\n","(np.argmax(Y_train, axis=1)[:300] - 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN3A1XB3eO68","executionInfo":{"status":"ok","timestamp":1650836028981,"user_tz":240,"elapsed":4,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"37b5f1cb-43b7-496a-fbfa-e7901495b398"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1,  1, -1,  1,  1, -1,  1,  0,  0,  0,  1,  0, -1,  1,  0,  0,  1,\n","        1,  0,  0,  1,  0, -1,  1,  0, -1,  0,  1,  0,  1,  1, -1,  0,  1,\n","        1, -1, -1,  0, -1,  0,  1,  1,  0, -1,  0,  1,  0,  1,  1,  1, -1,\n","       -1, -1,  0, -1,  0,  1,  1,  0,  1, -1,  1, -1,  0,  1,  0, -1,  1,\n","        0,  1,  1, -1, -1,  0,  1, -1, -1, -1, -1, -1,  0, -1,  0,  0, -1,\n","       -1, -1,  0,  1,  1,  1,  1, -1, -1, -1, -1,  0,  1,  0, -1,  1, -1,\n","        0, -1, -1,  0,  1, -1,  0, -1,  0,  0,  0,  1,  0, -1, -1,  1, -1,\n","       -1,  0, -1,  0,  0,  1, -1, -1, -1, -1,  0, -1,  1,  0,  1,  1, -1,\n","       -1,  1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1, -1, -1,  0, -1,  1,\n","       -1,  0,  1,  1,  1,  1,  0,  0, -1, -1,  1,  1,  0,  0,  0,  1,  0,\n","        0,  0,  0,  1,  1,  1, -1,  0,  1, -1, -1, -1,  1,  1,  0,  1, -1,\n","        1,  1,  1,  0,  0,  0,  0, -1,  1, -1,  1, -1,  1,  1,  1,  1,  0,\n","        0,  1,  1,  1,  1, -1, -1, -1,  0,  0,  1, -1, -1,  0,  1, -1,  0,\n","        1, -1,  1, -1,  0,  0,  0, -1, -1,  1,  1,  0, -1,  1,  1, -1,  1,\n","        1,  0,  0, -1,  0,  1, -1,  0,  0, -1,  1, -1,  0, -1,  1, -1, -1,\n","       -1,  0, -1,  0, -1,  0, -1, -1,  1,  0,  0,  1,  0, -1, -1, -1,  1,\n","       -1,  1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  0,  1,  0,  0,\n","        0,  1, -1,  0, -1,  1, -1, -1, -1,  1,  1])"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Word Vector Embedding\n","> create the word mappings for our specific dataset "],"metadata":{"id":"kxk_ZE5dF47X"}},{"cell_type":"code","source":["from keras.datasets import imdb\n","import pandas as pd\n","import numpy as np\n","from keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n","from keras.layers.embeddings import Embedding\n","from keras.models import Model\n","import string\n","import re\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing.sequence import pad_sequences\n","import keras\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"9I6GWlwgILND","executionInfo":{"status":"ok","timestamp":1650836029085,"user_tz":240,"elapsed":5,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# create list of unique words in sentences\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(X_train)\n","\n","#creates dictionary of each {word: index}\n","words_to_index = tokenizer.word_index\n","words_to_index"],"metadata":{"id":"CkCfFj2pILNC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836029864,"user_tz":240,"elapsed":782,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"5d8ce2a3-1936-458d-fa25-d9f8a077db24"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'and': 1,\n"," 'the': 2,\n"," 'of': 3,\n"," 'al': 4,\n"," 'et': 5,\n"," 'in': 6,\n"," 'to': 7,\n"," 'a': 8,\n"," 'for': 9,\n"," 'is': 10,\n"," 'that': 11,\n"," 'as': 12,\n"," 'have': 13,\n"," 'are': 14,\n"," 'on': 15,\n"," 'been': 16,\n"," 'church': 17,\n"," 'used': 18,\n"," 'we': 19,\n"," 'this': 20,\n"," 'information': 21,\n"," 'by': 22,\n"," 'with': 23,\n"," 'method': 24,\n"," 'not': 25,\n"," 'models': 26,\n"," 'hanks': 27,\n"," 'model': 28,\n"," 'tagging': 29,\n"," 'be': 30,\n"," 'but': 31,\n"," 'which': 32,\n"," 'can': 33,\n"," 'has': 34,\n"," 'word': 35,\n"," 'performance': 36,\n"," 'approach': 37,\n"," 'cutting': 38,\n"," 'translation': 39,\n"," 'data': 40,\n"," 'words': 41,\n"," 'than': 42,\n"," 'from': 43,\n"," 'based': 44,\n"," 'mutual': 45,\n"," 'was': 46,\n"," 'wsd': 47,\n"," 'such': 48,\n"," 'our': 49,\n"," 'similarity': 50,\n"," 'smith': 51,\n"," 'language': 52,\n"," 'approaches': 53,\n"," 'it': 54,\n"," 'more': 55,\n"," 'semantic': 56,\n"," 'lin': 57,\n"," 'results': 58,\n"," 'brown': 59,\n"," 'all': 60,\n"," 'proposed': 61,\n"," 'similar': 62,\n"," 'other': 63,\n"," 'using': 64,\n"," 'or': 65,\n"," 'an': 66,\n"," 'shown': 67,\n"," 'statistical': 68,\n"," 'dependency': 69,\n"," 'methods': 70,\n"," 'also': 71,\n"," 'most': 72,\n"," 'measure': 73,\n"," 'collocations': 74,\n"," 'wu': 75,\n"," 'pos': 76,\n"," 'over': 77,\n"," 'markov': 78,\n"," 'turney': 79,\n"," 'work': 80,\n"," 'when': 81,\n"," 'their': 82,\n"," 'machine': 83,\n"," 'mi': 84,\n"," 'including': 85,\n"," 'one': 86,\n"," 'unsupervised': 87,\n"," 'two': 88,\n"," 'reported': 89,\n"," 'algorithm': 90,\n"," 'johnson': 91,\n"," 'large': 92,\n"," 'brants': 93,\n"," 'these': 94,\n"," 'carpuat': 95,\n"," 'wikipedia': 96,\n"," 'kazama': 97,\n"," 'torisawa': 98,\n"," 'training': 99,\n"," 'applications': 100,\n"," 'available': 101,\n"," 'hidden': 102,\n"," 'collins': 103,\n"," 'eg': 104,\n"," 'thus': 105,\n"," 'well': 106,\n"," 'since': 107,\n"," 'use': 108,\n"," 'lexical': 109,\n"," 'mckeown': 110,\n"," 'jing': 111,\n"," 'systems': 112,\n"," 'corpora': 113,\n"," 'sentence': 114,\n"," 'its': 115,\n"," 'developed': 116,\n"," 'patterns': 117,\n"," 'gazetteer': 118,\n"," 'svore': 119,\n"," 'distributional': 120,\n"," 'rulebased': 121,\n"," 'no': 122,\n"," 'syntactic': 123,\n"," 'many': 124,\n"," 'english': 125,\n"," 'system': 126,\n"," 'outperform': 127,\n"," 'at': 128,\n"," 'lins': 129,\n"," 'text': 130,\n"," 'features': 131,\n"," 'modeling': 132,\n"," 'pointwise': 133,\n"," 'unlike': 134,\n"," 'b': 135,\n"," 'difficult': 136,\n"," 'hmm': 137,\n"," 'dagan': 138,\n"," 'there': 139,\n"," 'taggers': 140,\n"," 'resources': 141,\n"," 'version': 142,\n"," 'partofspeech': 143,\n"," 'pairclass': 144,\n"," 'better': 145,\n"," 'processing': 146,\n"," 'baseline': 147,\n"," 'improve': 148,\n"," 'although': 149,\n"," 'very': 150,\n"," 'networks': 151,\n"," 'same': 152,\n"," 'were': 153,\n"," 'each': 154,\n"," 'problem': 155,\n"," 'score': 156,\n"," 'found': 157,\n"," 'corpus': 158,\n"," 'number': 159,\n"," 'chan': 160,\n"," 'some': 161,\n"," 'disambiguation': 162,\n"," 'good': 163,\n"," 'several': 164,\n"," 'mihalcea': 165,\n"," 'jesscm': 166,\n"," 'relations': 167,\n"," 'uses': 168,\n"," 'widely': 169,\n"," 'applied': 170,\n"," 'sense': 171,\n"," 'however': 172,\n"," 'wordnet': 173,\n"," 'smt': 174,\n"," 'identify': 175,\n"," 'automatically': 176,\n"," 'brill': 177,\n"," 'techniques': 178,\n"," 'learning': 179,\n"," 'classes': 180,\n"," 'koehn': 181,\n"," 'zhang': 182,\n"," 'those': 183,\n"," 'recently': 184,\n"," 'only': 185,\n"," 'class': 186,\n"," 'due': 187,\n"," 'hindle': 188,\n"," 'pairs': 189,\n"," 'different': 190,\n"," 'lee': 191,\n"," 'ramage': 192,\n"," 'trained': 193,\n"," 'mcdonald': 194,\n"," 'related': 195,\n"," 'quality': 196,\n"," 'between': 197,\n"," 'recent': 198,\n"," 'jelinek': 199,\n"," 'hughes': 200,\n"," 'important': 201,\n"," 'much': 202,\n"," 'into': 203,\n"," 'success': 204,\n"," 'introduction': 205,\n"," 'etc': 206,\n"," 'lexicon': 207,\n"," 'rapp': 208,\n"," 'provides': 209,\n"," 'past': 210,\n"," 'byrne': 211,\n"," 'daelemans': 212,\n"," 'weeds': 213,\n"," 'possible': 214,\n"," 'smadja': 215,\n"," 'measures': 216,\n"," 'achieved': 217,\n"," 'higherorder': 218,\n"," 'may': 219,\n"," 'where': 220,\n"," 'ner': 221,\n"," 'equivalence': 222,\n"," 'notoriously': 223,\n"," 'cooccurrence': 224,\n"," 'schutze': 225,\n"," 'like': 226,\n"," 'task': 227,\n"," 'expected': 228,\n"," 'distributions': 229,\n"," 'structure': 230,\n"," 'nivre': 231,\n"," 'weischedel': 232,\n"," 'tasks': 233,\n"," 'wellknown': 234,\n"," 'context': 235,\n"," 'terms': 236,\n"," 'set': 237,\n"," 'result': 238,\n"," 'both': 239,\n"," 'first': 240,\n"," 'annotated': 241,\n"," 's': 242,\n"," 'tags': 243,\n"," 'successfully': 244,\n"," 'best': 245,\n"," 'biemann': 246,\n"," 'marcu': 247,\n"," 'without': 248,\n"," 'hoang': 249,\n"," 'require': 250,\n"," 'test': 251,\n"," 'edge': 252,\n"," 'phrases': 253,\n"," 'note': 254,\n"," 'out': 255,\n"," 'feature': 256,\n"," 'introduced': 257,\n"," 'generated': 258,\n"," 'derose': 259,\n"," 'clusters': 260,\n"," 'comparison': 261,\n"," 'alignment': 262,\n"," 'morphological': 263,\n"," 'toutanova': 264,\n"," 'memorybased': 265,\n"," 'promise': 266,\n"," 'abney': 267,\n"," 'f': 268,\n"," 'extracted': 269,\n"," 'combination': 270,\n"," 'ambiguity': 271,\n"," 'among': 272,\n"," 'requiring': 273,\n"," 'representations': 274,\n"," 'property': 275,\n"," 'events': 276,\n"," 'general': 277,\n"," 'interesting': 278,\n"," 'association': 279,\n"," 'natural': 280,\n"," 'weights': 281,\n"," 'against': 282,\n"," 'even': 283,\n"," 'representation': 284,\n"," 'outperformed': 285,\n"," 'thirdparty': 286,\n"," 'potential': 287,\n"," 'obtaining': 288,\n"," 'weir': 289,\n"," 'web': 290,\n"," 'pedersen': 291,\n"," 'straightforward': 292,\n"," 'estimation': 293,\n"," 'pereira': 294,\n"," 'various': 295,\n"," 'observed': 296,\n"," 'caveat': 297,\n"," 'reliance': 298,\n"," 'studies': 299,\n"," 'want': 300,\n"," 'outperforms': 301,\n"," 'discover': 302,\n"," 'contrast': 303,\n"," 'koo': 304,\n"," 'papers': 305,\n"," 'looked': 306,\n"," 'simpler': 307,\n"," 'procedure': 308,\n"," 'respectively': 309,\n"," 'existing': 310,\n"," 'smaller': 311,\n"," 'while': 312,\n"," 'automatic': 313,\n"," 'suzuki': 314,\n"," 'amount': 315,\n"," 'wordnetbased': 316,\n"," 'lexicography': 317,\n"," 'detailed': 318,\n"," 'chains': 319,\n"," 'smoothing': 320,\n"," 'phrase': 321,\n"," 'others': 322,\n"," 'japanese': 323,\n"," 'stateoftheart': 324,\n"," 'interest': 325,\n"," 'they': 326,\n"," 'publicly': 327,\n"," 'examined': 328,\n"," 'synpara': 329,\n"," 'formalized': 330,\n"," 'lund': 331,\n"," 'burgess': 332,\n"," 'edmonds': 333,\n"," 'lemaire': 334,\n"," 'denhiere': 335,\n"," 'senses': 336,\n"," 'who': 337,\n"," 'increases': 338,\n"," 'preferred': 339,\n"," 'richer': 340,\n"," 'largest': 341,\n"," 'though': 342,\n"," 'statistically': 343,\n"," 'frequently': 344,\n"," 'slightly': 345,\n"," 'summarization': 346,\n"," 'because': 347,\n"," 'marginal': 348,\n"," 'either': 349,\n"," 'supervised': 350,\n"," 'optimal': 351,\n"," 'approximately': 352,\n"," 'embeds': 353,\n"," 'edges': 354,\n"," 'cross': 355,\n"," 'offering': 356,\n"," 'entries': 357,\n"," 'see': 358,\n"," 'despite': 359,\n"," 'kumar': 360,\n"," 'unfortunately': 361,\n"," 'generalization': 362,\n"," 'frequency': 363,\n"," 'problems': 364,\n"," 'parameter': 365,\n"," 'dropped': 366,\n"," 'freely': 367,\n"," 'following': 368,\n"," 'tested': 369,\n"," 'significance': 370,\n"," 'rare': 371,\n"," 'modest': 372,\n"," 'always': 373,\n"," 'understood': 374,\n"," 'conll': 375,\n"," 'showing': 376,\n"," 'modify': 377,\n"," 'manually': 378,\n"," 'unable': 379,\n"," 'carry': 380,\n"," 'mt': 381,\n"," 'accuracy': 382,\n"," 'length': 383,\n"," 'function': 384,\n"," 'hybrid': 385,\n"," 'research': 386,\n"," 'rules': 387,\n"," 'monotonic': 388,\n"," 'collocational': 389,\n"," 'brills': 390,\n"," 'demonstrate': 391,\n"," 'unacceptable': 392,\n"," 'lowcount': 393,\n"," 'beyond': 394,\n"," 'maximumentropy': 395,\n"," 'rathnaparki': 396,\n"," 'cyclic': 397,\n"," 'listing': 398,\n"," 'surprisingly': 399,\n"," 'example': 400,\n"," 'potentially': 401,\n"," 'status': 402,\n"," 'overemphasising': 403,\n"," 'configurations': 404,\n"," 'purely': 405,\n"," 'inspect': 406,\n"," 'recognition': 407,\n"," 'together': 408,\n"," 'limitation': 409,\n"," 'points': 410,\n"," 'higher': 411,\n"," 'ngram': 412,\n"," 'simple': 413,\n"," 'sentences': 414,\n"," 't': 415,\n"," 'minnen': 416,\n"," 'sophisticated': 417,\n"," 'twoword': 418,\n"," 'arbitrary': 419,\n"," 'fscores': 420,\n"," 'researchers': 421,\n"," 'goes': 422,\n"," 'deals': 423,\n"," 'pantel': 424,\n"," 'source': 425,\n"," 'phrasebased': 426,\n"," 'distribution': 427,\n"," 'poesio': 428,\n"," 'statistics': 429,\n"," 'external': 430,\n"," 'lapata': 431,\n"," 'weight': 432,\n"," 'high': 433,\n"," 'decoding': 434,\n"," 'parsing': 435,\n"," 'previous': 436,\n"," 'tree': 437,\n"," 'space': 438,\n"," 'joint': 439,\n"," 'probabilities': 440,\n"," 'cucerzan': 441,\n"," 'retrieval': 442,\n"," 'search': 443,\n"," 'given': 444,\n"," 'm': 445,\n"," 'p': 446,\n"," 'zettlemoyer': 447,\n"," 'time': 448,\n"," 'explored': 449,\n"," 'years': 450,\n"," 'described': 451,\n"," 'liu': 452,\n"," 'gram': 453,\n"," 'whether': 454,\n"," 'xerox': 455,\n"," 'xy': 456,\n"," 'efficient': 457,\n"," 'selection': 458,\n"," 'additional': 459,\n"," 'acquisition': 460,\n"," 'useful': 461,\n"," 'table': 462,\n"," 'lead': 463,\n"," 'then': 464,\n"," 'clustering': 465,\n"," 'knowledge': 466,\n"," 'functions': 467,\n"," 'hovy': 468,\n"," 'pair': 469,\n"," 'effective': 470,\n"," 'spaces': 471,\n"," 'yarowsky': 472,\n"," 'resnik': 473,\n"," 'dolan': 474,\n"," 'noun': 475,\n"," 'charniak': 476,\n"," 'huang': 477,\n"," 'almuhareb': 478,\n"," 'speech': 479,\n"," 'include': 480,\n"," 'contextual': 481,\n"," 'ability': 482,\n"," 'informationtheoretic': 483,\n"," 'reordering': 484,\n"," 'advances': 485,\n"," 'improvement': 486,\n"," 'integrating': 487,\n"," 'bleu': 488,\n"," 'improvements': 489,\n"," 'parse': 490,\n"," 'component': 491,\n"," 'do': 492,\n"," 'ways': 493,\n"," 'entropy': 494,\n"," 'starting': 495,\n"," 'metric': 496,\n"," 'editing': 497,\n"," 'factored': 498,\n"," 'process': 499,\n"," 'sets': 500,\n"," 'unlabeled': 501,\n"," 'show': 502,\n"," 'luk': 503,\n"," 'parsers': 504,\n"," 'analysis': 505,\n"," 'improved': 506,\n"," 'five': 507,\n"," 'maximum': 508,\n"," 'perform': 509,\n"," 'y': 510,\n"," 'classbased': 511,\n"," 'constructed': 512,\n"," 'mccarthy': 513,\n"," 'pmi': 514,\n"," 'negative': 515,\n"," 'kurland': 516,\n"," 'backoff': 517,\n"," 'instance': 518,\n"," 'category': 519,\n"," 'if': 520,\n"," 'ravichandran': 521,\n"," 'usually': 522,\n"," 'values': 523,\n"," 'nlp': 524,\n"," 'powerful': 525,\n"," 'readily': 526,\n"," 'tagger': 527,\n"," 'tag': 528,\n"," 'during': 529,\n"," 'commonly': 530,\n"," 'demonstrated': 531,\n"," 'particular': 532,\n"," 'makes': 533,\n"," 'variety': 534,\n"," 'd': 535,\n"," 'distributed': 536,\n"," 'framework': 537,\n"," 'eisner': 538,\n"," 'volk': 539,\n"," 'x': 540,\n"," 'wang': 541,\n"," 'size': 542,\n"," 'compute': 543,\n"," 'them': 544,\n"," 'experiments': 545,\n"," 'goldwater': 546,\n"," 'will': 547,\n"," 'helps': 548,\n"," 'curran': 549,\n"," 'goel': 550,\n"," 'fraser': 551,\n"," 'describe': 552,\n"," 'ratio': 553,\n"," 'promising': 554,\n"," 'compared': 555,\n"," 'similaritybased': 556,\n"," 'tishby': 557,\n"," 'intuitively': 558,\n"," 'appealing': 559,\n"," 'i': 560,\n"," 'per': 561,\n"," 'might': 562,\n"," 'dependencies': 563,\n"," 'dictionaries': 564,\n"," 'simplicity': 565,\n"," 'thesaurus': 566,\n"," 'log': 567,\n"," 'lopez': 568,\n"," 'literature': 569,\n"," 'known': 570,\n"," 'entity': 571,\n"," 'grammars': 572,\n"," 'algorithms': 573,\n"," 'chen': 574,\n"," 'evans': 575,\n"," 'knight': 576,\n"," 'cooccurrences': 577,\n"," 'name': 578,\n"," 'accurate': 579,\n"," 'states': 580,\n"," 'griffiths': 581,\n"," 'associations': 582,\n"," 'considerable': 583,\n"," 'pattern': 584,\n"," 'em': 585,\n"," 'according': 586,\n"," 'wflog': 587,\n"," 'countwf': 588,\n"," 'countf': 589,\n"," 'relatedness': 590,\n"," 'compare': 591,\n"," 'articles': 592,\n"," 'scale': 593,\n"," 'output': 594,\n"," 'hmms': 595,\n"," 'erkan': 596,\n"," 'radev': 597,\n"," 'linguistic': 598,\n"," 'previously': 599,\n"," 'directly': 600,\n"," 'scheme': 601,\n"," 'semisupervised': 602,\n"," 'relation': 603,\n"," 'concepts': 604,\n"," 'section': 605,\n"," 'showed': 606,\n"," 'named': 607,\n"," 'contexts': 608,\n"," 'resolution': 609,\n"," 'being': 610,\n"," 'k': 611,\n"," 'typically': 612,\n"," 'classification': 613,\n"," 'computed': 614,\n"," 'done': 615,\n"," 'reranking': 616,\n"," 'issue': 617,\n"," 'mani': 618,\n"," 'main': 619,\n"," 'reduction': 620,\n"," 'less': 621,\n"," 'types': 622,\n"," 'page': 623,\n"," 'tarau': 624,\n"," 'c': 625,\n"," 'range': 626,\n"," 'prediction': 627,\n"," 'great': 628,\n"," 'here': 629,\n"," 'grammar': 630,\n"," 'obtained': 631,\n"," 'target': 632,\n"," 'instead': 633,\n"," 'grouping': 634,\n"," 'nouns': 635,\n"," 'w': 636,\n"," 'side': 637,\n"," 'claim': 638,\n"," 'extremely': 639,\n"," 'whereas': 640,\n"," 'give': 641,\n"," 'now': 642,\n"," 'stochastic': 643,\n"," 'scoring': 644,\n"," 'latent': 645,\n"," 'moses': 646,\n"," 'evaluation': 647,\n"," 'article': 648,\n"," 'extract': 649,\n"," 'compression': 650,\n"," 'gates': 651,\n"," 'bloedorn': 652,\n"," 'coefficientmanning': 653,\n"," 'schueutze': 654,\n"," 'independent': 655,\n"," 'j': 656,\n"," 'positive': 657,\n"," 'n': 658,\n"," 'verbs': 659,\n"," 'partial': 660,\n"," 'wide': 661,\n"," 'state': 662,\n"," 'study': 663,\n"," 'galley': 664,\n"," 'definition': 665,\n"," 'calculate': 666,\n"," 'employing': 667,\n"," 'ruge': 668,\n"," 'goodman': 669,\n"," 'relevant': 670,\n"," 'employed': 671,\n"," 'took': 672,\n"," 'groups': 673,\n"," 'able': 674,\n"," 'second': 675,\n"," 'paper': 676,\n"," 'made': 677,\n"," 'sequencebased': 678,\n"," 'matrix': 679,\n"," 'cases': 680,\n"," 'schmid': 681,\n"," 'hand': 682,\n"," 'markovitch': 683,\n"," 'label': 684,\n"," 'inventory': 685,\n"," 'furthermore': 686,\n"," 'probability': 687,\n"," 'moore': 688,\n"," 'build': 689,\n"," 'fact': 690,\n"," 'works': 691,\n"," 'gazetteers': 692,\n"," 'written': 693,\n"," 'robust': 694,\n"," 'verbobject': 695,\n"," 'frequencies': 696,\n"," 'distance': 697,\n"," 'produce': 698,\n"," 'bayesian': 699,\n"," 'brin': 700,\n"," 'kleinberg': 701,\n"," 'purpose': 702,\n"," 'shows': 703,\n"," 'annotation': 704,\n"," 'annotators': 705,\n"," 'involve': 706,\n"," 'identification': 707,\n"," 'create': 708,\n"," 'competitive': 709,\n"," 'what': 710,\n"," 'train': 711,\n"," 'henderson': 712,\n"," 'pp': 713,\n"," 'toral': 714,\n"," 'coefficient': 715,\n"," 'except': 716,\n"," 'verb': 717,\n"," 'topic': 718,\n"," 'surpass': 719,\n"," 'pad': 720,\n"," 'categorisation': 721,\n"," 'equally': 722,\n"," 'effect': 723,\n"," 'chelba': 724,\n"," 'forestbased': 725,\n"," 'comparisons': 726,\n"," 'van': 727,\n"," 'yield': 728,\n"," 'integration': 729,\n"," 'alternative': 730,\n"," 'erk': 731,\n"," 'estimated': 732,\n"," 'form': 733,\n"," 'report': 734,\n"," 'metrics': 735,\n"," 'nist': 736,\n"," 'meteor': 737,\n"," 'news': 738,\n"," 'novel': 739,\n"," 'och': 740,\n"," 'refined': 741,\n"," 'quirk': 742,\n"," 'published': 743,\n"," 'grishman': 744,\n"," 'domain': 745,\n"," 'bilingual': 746,\n"," 'reason': 747,\n"," 'subjectverb': 748,\n"," 'motivation': 749,\n"," 'strube': 750,\n"," 'exceptions': 751,\n"," 'solve': 752,\n"," 'exploiting': 753,\n"," 'handbuilt': 754,\n"," 'incorporate': 755,\n"," 'structures': 756,\n"," 'solution': 757,\n"," 'ie': 758,\n"," 'hyperlinked': 759,\n"," 'pages': 760,\n"," 'complete': 761,\n"," 'sequences': 762,\n"," 'realized': 763,\n"," 'sahlgren': 764,\n"," 'baroni': 765,\n"," 'window': 766,\n"," 'arguably': 767,\n"," 'treebanks': 768,\n"," 'highly': 769,\n"," 'macken': 770,\n"," 'wikifs': 771,\n"," 'defined': 772,\n"," 'choose': 773,\n"," 'titov': 774,\n"," 'utilized': 775,\n"," 'luo': 776,\n"," 'iii': 777,\n"," 'significant': 778,\n"," 'inspiration': 779,\n"," 'pioneering': 780,\n"," 'fundamentally': 781,\n"," 'corelex': 782,\n"," 'reasonably': 783,\n"," 'bayes': 784,\n"," 'dynamically': 785,\n"," 'determine': 786,\n"," 'under': 787,\n"," 'signatures': 788,\n"," 'ratnaparkhi': 789,\n"," 'finitestate': 790,\n"," 'hyponymy': 791,\n"," 'creating': 792,\n"," 'similarword': 793,\n"," 'jaccard': 794,\n"," 'gildea': 795,\n"," 'considered': 796,\n"," 'jiang': 797,\n"," 'conrath': 798,\n"," 'lavie': 799,\n"," 'string': 800,\n"," 'leverage': 801,\n"," 'critical': 802,\n"," 'sterling': 803,\n"," 'classifier': 804,\n"," 'dredze': 805,\n"," 'fscore': 806,\n"," 'collocation': 807,\n"," 'pasca': 808,\n"," 'crosslingual': 809,\n"," 'vossen': 810,\n"," 'efficiently': 811,\n"," 'pure': 812,\n"," 'standard': 813,\n"," 'popular': 814,\n"," 'neglected': 815,\n"," 'notable': 816,\n"," 'kupiec': 817,\n"," 'linguistics': 818,\n"," 'palmers': 819,\n"," 'palmer': 820,\n"," 'resniks': 821,\n"," 'input': 822,\n"," 'roark': 823,\n"," 'computational': 824,\n"," 'complementary': 825,\n"," 'centrality': 826,\n"," 'choueka': 827,\n"," 'germantoenglish': 828,\n"," 'candidates': 829,\n"," 'could': 830,\n"," 'provide': 831,\n"," 'art': 832,\n"," 'expensive': 833,\n"," 'frenchenglish': 834,\n"," 'liang': 835,\n"," 'insights': 836,\n"," 'linguisticallymotivated': 837,\n"," 'syntaxbased': 838,\n"," 'jansche': 839,\n"," 'significantly': 840,\n"," 'performing': 841,\n"," 'extensively': 842,\n"," 'minimizing': 843,\n"," 'capture': 844,\n"," 'possibilities': 845,\n"," 'goldberg': 846,\n"," 'keller': 847,\n"," 'dice': 848,\n"," 'none': 849,\n"," 'extraction': 850,\n"," 'weighting': 851,\n"," 'chklovski': 852,\n"," 'instances': 853,\n"," 'naive': 854,\n"," 'let': 855,\n"," 'mercer': 856,\n"," 'beginnings': 857,\n"," 'currently': 858,\n"," 'trillions': 859,\n"," 'explained': 860,\n"," 'leads': 861,\n"," 'trees': 862,\n"," 'expectations': 863,\n"," 'inverse': 864,\n"," 'halteren': 865,\n"," 'schneider': 866,\n"," 'aproaches': 867,\n"," 'seen': 868,\n"," 'tricky': 869,\n"," 'evident': 870,\n"," 'conflicting': 871,\n"," 'conclusions': 872,\n"," 'marcus': 873,\n"," 'discriminative': 874,\n"," 'candidate': 875,\n"," 'retrainable': 876,\n"," 'datasets': 877,\n"," 'fundamental': 878,\n"," 'ir': 879,\n"," 'viewed': 880,\n"," 'ambiguous': 881,\n"," 'assigned': 882,\n"," 'predefined': 883,\n"," 'suggests': 884,\n"," 'hints': 885,\n"," 'doddington': 886,\n"," 'banerjee': 887,\n"," 'ter': 888,\n"," 'snover': 889,\n"," 'wer': 890,\n"," 'max': 891,\n"," 'schemes': 892,\n"," 'inchmm': 893,\n"," 'maxbleu': 894,\n"," 'incorporating': 895,\n"," 'about': 896,\n"," 'gale': 897,\n"," 'map': 898,\n"," 'sparse': 899,\n"," 'lms': 900,\n"," 'google': 901,\n"," 'pruning': 902,\n"," 'emami': 903,\n"," 'skepticism': 904,\n"," 'actually': 905,\n"," 'clough': 906,\n"," 'stevenson': 907,\n"," 'hope': 908,\n"," 'questionanswering': 909,\n"," 'simplication': 910,\n"," 'summarisation': 911,\n"," 'benet': 912,\n"," 'would': 913,\n"," 'how': 914,\n"," 'coverage': 915,\n"," 'strengths': 916,\n"," 'detail': 917,\n"," 'lacatusu': 918,\n"," 'leading': 919,\n"," 'multiple': 920,\n"," 'merialdo': 921,\n"," 'spans': 922,\n"," 'munoz': 923,\n"," 'fluency': 924,\n"," 'hold': 925,\n"," 'actual': 926,\n"," 'zwarts': 927,\n"," 'dras': 928,\n"," 'adding': 929,\n"," 'advantage': 930,\n"," 'parameters': 931,\n"," 'online': 932,\n"," 'eigenvector': 933,\n"," 'inventories': 934,\n"," 'gimenez': 935,\n"," 'marquez': 936,\n"," 'stupid': 937,\n"," 'kneserney': 938,\n"," 'counts': 939,\n"," 'matrixtree': 940,\n"," 'satta': 941,\n"," 'probabilistic': 942,\n"," 'risk': 943,\n"," 'interested': 944,\n"," 'grouped': 945,\n"," 'dickinson': 946,\n"," 'tseng': 947,\n"," 'languageprocessingnlpapplications': 948,\n"," 'suchasprepositional': 949,\n"," 'attachment': 950,\n"," 'otheranaphora': 951,\n"," 'spellingcorrection': 952,\n"," 'confusablewordsetdisambiguation': 953,\n"," 'modjeska': 954,\n"," 'atterer': 955,\n"," 'daume': 956,\n"," 'sequence': 957,\n"," 'probably': 958,\n"," 'dened': 959,\n"," 'assumed': 960,\n"," 'correspond': 961,\n"," 'strong': 962,\n"," 'analogy': 963,\n"," 'anotherstateoftheartwsdengineacombination': 964,\n"," 'boosting': 965,\n"," 'kernel': 966,\n"," 'pca': 967,\n"," 'consideration': 968,\n"," 'adapt': 969,\n"," 'conclude': 970,\n"," 'noting': 971,\n"," 'automated': 972,\n"," 'letter': 973,\n"," 'parameterspipikof': 974,\n"," 'observationsy': 975,\n"," 'psypipik': 976,\n"," 'tproductdisplay': 977,\n"," 'pststpytst': 978,\n"," 'clearly': 979,\n"," 'poor': 980,\n"," 'kirchoff': 981,\n"," 'three': 982,\n"," 'dermatas': 983,\n"," 'independence': 984,\n"," 'accuracies': 985,\n"," 'zitouni': 986,\n"," 'equation': 987,\n"," 'lemmas': 988,\n"," 'synonymy': 989,\n"," 'hypernymy': 990,\n"," 'antonymy': 991,\n"," 'widelyused': 992,\n"," 'nombank': 993,\n"," 'infers': 994,\n"," 'constructedis': 995,\n"," 'manli': 996,\n"," 'examples': 997,\n"," 'greinstette': 998,\n"," 'summationtext': 999,\n"," 'wikipediabased': 1000,\n"," ...}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["#function to read GloCe Vector file\n","def read_glove_vector(glove_vec):\n","  with open(glove_vec, 'r', encoding='UTF-8') as f:\n","    words = set()\n","    word_to_vec_map = {}\n","    for line in f:\n","      w_line = line.split()\n","      curr_word = w_line[0]\n","      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n","\n","\n","\n","  return word_to_vec_map"],"metadata":{"id":"_aaj6FllILNC","executionInfo":{"status":"ok","timestamp":1650836029866,"user_tz":240,"elapsed":8,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# read in GloVe vector from Google Drive (premade mapping of words to be used for sentiment analysis)\n","word_to_vec_map = read_glove_vector('/content/drive/MyDrive/UMD - senior year/spring 2022/439D/project/glove.6B.50d.txt')"],"metadata":{"id":"K3OJwRicILND","executionInfo":{"status":"ok","timestamp":1650836036336,"user_tz":240,"elapsed":6475,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Embedding\n","\n","\n","# create embedding matrix (all words in GloVe vector assigned to correct value matrix, all others assigend to 0 vector)\n","vocab_len = len(words_to_index) + 1\n","embed_vector_len = word_to_vec_map['moon'].shape[0]\n","\n","emb_matrix = np.zeros((vocab_len, embed_vector_len))\n","\n","\n","#get glove coordinates of words that are in BOTH glove list and in training data sentences \n","for word, index in words_to_index.items():\n","  embedding_vector = word_to_vec_map.get(word)\n","  if embedding_vector is not None:\n","    print(word)\n","    emb_matrix[index, :] = embedding_vector\n","\n","embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"],"metadata":{"id":"SXC7zvfSILND","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836036886,"user_tz":240,"elapsed":556,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"0900d816-20b5-4eab-a8f3-e7d83436ae18"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["and\n","the\n","of\n","al\n","et\n","in\n","to\n","a\n","for\n","is\n","that\n","as\n","have\n","are\n","on\n","been\n","church\n","used\n","we\n","this\n","information\n","by\n","with\n","method\n","not\n","models\n","hanks\n","model\n","tagging\n","be\n","but\n","which\n","can\n","has\n","word\n","performance\n","approach\n","cutting\n","translation\n","data\n","words\n","than\n","from\n","based\n","mutual\n","was\n","wsd\n","such\n","our\n","similarity\n","smith\n","language\n","approaches\n","it\n","more\n","semantic\n","lin\n","results\n","brown\n","all\n","proposed\n","similar\n","other\n","using\n","or\n","an\n","shown\n","statistical\n","dependency\n","methods\n","also\n","most\n","measure\n","collocations\n","wu\n","pos\n","over\n","markov\n","turney\n","work\n","when\n","their\n","machine\n","mi\n","including\n","one\n","unsupervised\n","two\n","reported\n","algorithm\n","johnson\n","large\n","these\n","wikipedia\n","kazama\n","training\n","applications\n","available\n","hidden\n","collins\n","eg\n","thus\n","well\n","since\n","use\n","lexical\n","mckeown\n","jing\n","systems\n","corpora\n","sentence\n","its\n","developed\n","patterns\n","gazetteer\n","distributional\n","no\n","syntactic\n","many\n","english\n","system\n","outperform\n","at\n","lins\n","text\n","features\n","modeling\n","pointwise\n","unlike\n","b\n","difficult\n","hmm\n","dagan\n","there\n","taggers\n","resources\n","version\n","better\n","processing\n","baseline\n","improve\n","although\n","very\n","networks\n","same\n","were\n","each\n","problem\n","score\n","found\n","corpus\n","number\n","chan\n","some\n","disambiguation\n","good\n","several\n","mihalcea\n","relations\n","uses\n","widely\n","applied\n","sense\n","however\n","wordnet\n","smt\n","identify\n","automatically\n","brill\n","techniques\n","learning\n","classes\n","koehn\n","zhang\n","those\n","recently\n","only\n","class\n","due\n","hindle\n","pairs\n","different\n","lee\n","ramage\n","trained\n","mcdonald\n","related\n","quality\n","between\n","recent\n","jelinek\n","hughes\n","important\n","much\n","into\n","success\n","introduction\n","etc\n","lexicon\n","rapp\n","provides\n","past\n","byrne\n","weeds\n","possible\n","smadja\n","measures\n","achieved\n","may\n","where\n","ner\n","equivalence\n","notoriously\n","schutze\n","like\n","task\n","expected\n","distributions\n","structure\n","tasks\n","wellknown\n","context\n","terms\n","set\n","result\n","both\n","first\n","annotated\n","s\n","tags\n","successfully\n","best\n","marcu\n","without\n","hoang\n","require\n","test\n","edge\n","phrases\n","note\n","out\n","feature\n","introduced\n","generated\n","derose\n","clusters\n","comparison\n","alignment\n","morphological\n","promise\n","abney\n","f\n","extracted\n","combination\n","ambiguity\n","among\n","requiring\n","representations\n","property\n","events\n","general\n","interesting\n","association\n","natural\n","weights\n","against\n","even\n","representation\n","outperformed\n","potential\n","obtaining\n","weir\n","web\n","pedersen\n","straightforward\n","estimation\n","pereira\n","various\n","observed\n","caveat\n","reliance\n","studies\n","want\n","outperforms\n","discover\n","contrast\n","koo\n","papers\n","looked\n","simpler\n","procedure\n","respectively\n","existing\n","smaller\n","while\n","automatic\n","suzuki\n","amount\n","lexicography\n","detailed\n","chains\n","smoothing\n","phrase\n","others\n","japanese\n","interest\n","they\n","publicly\n","examined\n","formalized\n","lund\n","burgess\n","edmonds\n","lemaire\n","senses\n","who\n","increases\n","preferred\n","richer\n","largest\n","though\n","statistically\n","frequently\n","slightly\n","summarization\n","because\n","marginal\n","either\n","supervised\n","optimal\n","approximately\n","embeds\n","edges\n","cross\n","offering\n","entries\n","see\n","despite\n","kumar\n","unfortunately\n","generalization\n","frequency\n","problems\n","parameter\n","dropped\n","freely\n","following\n","tested\n","significance\n","rare\n","modest\n","always\n","understood\n","showing\n","modify\n","manually\n","unable\n","carry\n","mt\n","accuracy\n","length\n","function\n","hybrid\n","research\n","rules\n","monotonic\n","demonstrate\n","unacceptable\n","beyond\n","cyclic\n","listing\n","surprisingly\n","example\n","potentially\n","status\n","configurations\n","purely\n","inspect\n","recognition\n","together\n","limitation\n","points\n","higher\n","simple\n","sentences\n","t\n","sophisticated\n","arbitrary\n","researchers\n","goes\n","deals\n","source\n","distribution\n","statistics\n","external\n","weight\n","high\n","decoding\n","parsing\n","previous\n","tree\n","space\n","joint\n","probabilities\n","retrieval\n","search\n","given\n","m\n","p\n","time\n","explored\n","years\n","described\n","liu\n","gram\n","whether\n","xerox\n","xy\n","efficient\n","selection\n","additional\n","acquisition\n","useful\n","table\n","lead\n","then\n","clustering\n","knowledge\n","functions\n","pair\n","effective\n","spaces\n","resnik\n","dolan\n","noun\n","huang\n","speech\n","include\n","contextual\n","ability\n","reordering\n","advances\n","improvement\n","integrating\n","bleu\n","improvements\n","parse\n","component\n","do\n","ways\n","entropy\n","starting\n","metric\n","editing\n","factored\n","process\n","sets\n","unlabeled\n","show\n","luk\n","parsers\n","analysis\n","improved\n","five\n","maximum\n","perform\n","y\n","constructed\n","mccarthy\n","pmi\n","negative\n","kurland\n","instance\n","category\n","if\n","ravichandran\n","usually\n","values\n","nlp\n","powerful\n","readily\n","tagger\n","tag\n","during\n","commonly\n","demonstrated\n","particular\n","makes\n","variety\n","d\n","distributed\n","framework\n","eisner\n","volk\n","x\n","wang\n","size\n","compute\n","them\n","experiments\n","goldwater\n","will\n","helps\n","curran\n","goel\n","fraser\n","describe\n","ratio\n","promising\n","compared\n","intuitively\n","appealing\n","i\n","per\n","might\n","dependencies\n","dictionaries\n","simplicity\n","thesaurus\n","log\n","lopez\n","literature\n","known\n","entity\n","grammars\n","algorithms\n","chen\n","evans\n","knight\n","name\n","accurate\n","states\n","griffiths\n","associations\n","considerable\n","pattern\n","em\n","according\n","relatedness\n","compare\n","articles\n","scale\n","output\n","hmms\n","erkan\n","radev\n","linguistic\n","previously\n","directly\n","scheme\n","relation\n","concepts\n","section\n","showed\n","named\n","contexts\n","resolution\n","being\n","k\n","typically\n","classification\n","computed\n","done\n","issue\n","mani\n","main\n","reduction\n","less\n","types\n","page\n","c\n","range\n","prediction\n","great\n","here\n","grammar\n","obtained\n","target\n","instead\n","grouping\n","nouns\n","w\n","side\n","claim\n","extremely\n","whereas\n","give\n","now\n","stochastic\n","scoring\n","latent\n","moses\n","evaluation\n","article\n","extract\n","compression\n","gates\n","independent\n","j\n","positive\n","n\n","verbs\n","partial\n","wide\n","state\n","study\n","galley\n","definition\n","calculate\n","employing\n","ruge\n","goodman\n","relevant\n","employed\n","took\n","groups\n","able\n","second\n","paper\n","made\n","matrix\n","cases\n","schmid\n","hand\n","label\n","inventory\n","furthermore\n","probability\n","moore\n","build\n","fact\n","works\n","gazetteers\n","written\n","robust\n","frequencies\n","distance\n","produce\n","bayesian\n","brin\n","kleinberg\n","purpose\n","shows\n","annotation\n","involve\n","identification\n","create\n","competitive\n","what\n","train\n","henderson\n","pp\n","toral\n","coefficient\n","except\n","verb\n","topic\n","surpass\n","pad\n","categorisation\n","equally\n","effect\n","comparisons\n","van\n","yield\n","integration\n","alternative\n","erk\n","estimated\n","form\n","report\n","metrics\n","nist\n","meteor\n","news\n","novel\n","och\n","refined\n","quirk\n","published\n","domain\n","bilingual\n","reason\n","motivation\n","strube\n","exceptions\n","solve\n","exploiting\n","handbuilt\n","incorporate\n","structures\n","solution\n","ie\n","hyperlinked\n","pages\n","complete\n","sequences\n","realized\n","baroni\n","window\n","arguably\n","highly\n","macken\n","defined\n","choose\n","titov\n","utilized\n","luo\n","iii\n","significant\n","inspiration\n","pioneering\n","fundamentally\n","reasonably\n","bayes\n","dynamically\n","determine\n","under\n","signatures\n","creating\n","jaccard\n","gildea\n","considered\n","jiang\n","conrath\n","lavie\n","string\n","leverage\n","critical\n","sterling\n","classifier\n","collocation\n","pasca\n","vossen\n","efficiently\n","pure\n","standard\n","popular\n","neglected\n","notable\n","linguistics\n","palmers\n","palmer\n","input\n","roark\n","computational\n","complementary\n","centrality\n","candidates\n","could\n","provide\n","art\n","expensive\n","liang\n","insights\n","significantly\n","performing\n","extensively\n","minimizing\n","capture\n","possibilities\n","goldberg\n","keller\n","dice\n","none\n","extraction\n","weighting\n","instances\n","naive\n","let\n","mercer\n","beginnings\n","currently\n","trillions\n","explained\n","leads\n","trees\n","expectations\n","inverse\n","schneider\n","seen\n","tricky\n","evident\n","conflicting\n","conclusions\n","marcus\n","discriminative\n","candidate\n","datasets\n","fundamental\n","ir\n","viewed\n","ambiguous\n","assigned\n","predefined\n","suggests\n","hints\n","doddington\n","banerjee\n","ter\n","wer\n","max\n","schemes\n","incorporating\n","about\n","gale\n","map\n","sparse\n","lms\n","google\n","pruning\n","emami\n","skepticism\n","actually\n","clough\n","stevenson\n","hope\n","benet\n","would\n","how\n","coverage\n","strengths\n","detail\n","leading\n","multiple\n","spans\n","munoz\n","fluency\n","hold\n","actual\n","dras\n","adding\n","advantage\n","parameters\n","online\n","eigenvector\n","inventories\n","gimenez\n","marquez\n","stupid\n","counts\n","satta\n","probabilistic\n","risk\n","interested\n","grouped\n","dickinson\n","tseng\n","attachment\n","modjeska\n","daume\n","sequence\n","probably\n","assumed\n","correspond\n","strong\n","analogy\n","boosting\n","kernel\n","pca\n","consideration\n","adapt\n","conclude\n","noting\n","automated\n","letter\n","clearly\n","poor\n","kirchoff\n","three\n","independence\n","accuracies\n","zitouni\n","equation\n","lemmas\n","synonymy\n","infers\n","manli\n","examples\n","learner\n","why\n","relies\n","allow\n","larger\n","golomb\n","coding\n","areas\n","dunning\n","parser\n","leverages\n","dedicated\n","efforts\n","mann\n","rather\n","cosine\n","decoder\n","application\n","albeit\n","proven\n","small\n","retain\n","v\n","prior\n","addition\n","any\n","interrupted\n","uninterrupted\n","extensive\n","human\n","scores\n","deploy\n","part\n","patrick\n","gauch\n","pwf\n","wf\n","adaptation\n","veale\n","sat\n","martin\n","common\n","make\n","chiang\n","projects\n","progress\n","shen\n","derived\n","relative\n","he\n","likelihood\n","just\n","later\n","etzioni\n","precise\n","completed\n","author\n","inc\n","suffix\n","arrays\n","surface\n","klein\n","benefits\n","module\n","often\n","aspect\n","narrow\n","down\n","distinguishing\n","people\n","focusing\n","person\n","rooth\n","graph\n","construction\n","thea\n","suitable\n","value\n","indeed\n","handle\n","presents\n","labeled\n","initial\n","way\n","reduced\n","expert\n","mechanical\n","turk\n","snow\n","solutions\n","ranging\n","type\n","order\n","attention\n","formula\n","theorem\n","structured\n","questions\n","achieving\n","seminal\n","unless\n","case\n","generate\n","estimates\n","estimate\n","focus\n","conditional\n","pietra\n","dictionary\n","find\n","texts\n","figure\n","list\n","unseen\n","term\n","minimum\n","katz\n","community\n","modified\n","precision\n","relational\n","aaa\n","phi\n","schuetze\n","srikant\n","rule\n","garside\n","leech\n","parsed\n","vectors\n","propose\n","strategy\n","gigantic\n","key\n","decoders\n","consequence\n","asymptotic\n","running\n","compelling\n","grammatical\n","properties\n","need\n","certainly\n","daunting\n","annotator\n","newly\n","access\n","pool\n","inexpensive\n","amazon\n","embedding\n","game\n","played\n","volunteers\n","von\n","ahn\n","manning\n","finkel\n","calzolari\n","bindi\n","optimization\n","technique\n","priors\n","associated\n","yang\n","includes\n","answer\n","attains\n","wiebe\n","thesauri\n","idea\n","maximization\n","lemma\n","studied\n","categories\n","another\n","generation\n","della\n","bahl\n","vector\n","local\n","measured\n","recall\n","reduce\n","within\n","extend\n","similarities\n","clarke\n","so\n","occur\n","e\n","wat\n","di\n","consider\n","estimating\n","presented\n","compound\n","received\n","gao\n","iterations\n","settings\n","global\n","specific\n","heuristic\n","after\n","further\n","low\n","along\n","take\n","linear\n","kim\n","mooney\n","account\n","unknown\n","logistic\n","computing\n","mining\n","extracting\n","full\n","does\n","malt\n","calculated\n","meaning\n","step\n","parallel\n","bootstrapping\n","taxonomy\n","ney\n","pagerank\n","definitions\n","obtain\n","independently\n","ij\n","g\n","inspired\n","factors\n","clark\n","direct\n","every\n","matsuzaki\n","times\n","describes\n","document\n","current\n","conventional\n","takes\n","norms\n","evidence\n","induction\n","leaf\n","likely\n","forms\n","ibm\n","rst\n","dat\n","nok\n","labels\n","bias\n","rosenfeld\n","authors\n","constraints\n","division\n","mrd\n","too\n","discussed\n","content\n","nonlocal\n","evaluations\n","interpretation\n","nonparametric\n","requires\n","variant\n","baker\n","putting\n","languages\n","shared\n","error\n","differences\n","errors\n","present\n","li\n","domains\n","synchronous\n","added\n","next\n","neighbors\n","bruce\n","expressions\n","rank\n","question\n","viterbi\n","pado\n","su\n","combine\n","adjectives\n","sentiment\n","determined\n","maximize\n","cohesion\n","evaluated\n","florian\n","leacock\n","lrm\n","total\n","hierarchical\n","learn\n","ff\n","his\n","tests\n","opinion\n","differs\n","induced\n","university\n","ranking\n","kind\n","deal\n","should\n","exponential\n","correlation\n","choice\n","rely\n","translations\n","select\n","top\n","random\n","cherry\n","layer\n","field\n","longer\n","root\n","discussion\n","frequent\n","span\n","below\n","specialist\n","roth\n","roughly\n","ng\n","singer\n","character\n","barzilay\n","mohammad\n","average\n","extension\n","transition\n","direction\n","inference\n","basis\n","sample\n","depends\n","variants\n","voutilainen\n","upper\n","base\n","parses\n","synonyms\n","means\n","lm\n","decision\n","aligned\n","new\n","variable\n","fixed\n","experimental\n","adj\n","generative\n","pisa\n","up\n","voorhees\n","building\n","ti\n","allows\n","setting\n","calculation\n","divided\n","early\n","cited\n","tend\n","observe\n","ando\n","correlate\n","summary\n","semantics\n","overview\n","projective\n","achieve\n","finally\n","major\n","boundaries\n","examine\n","had\n","included\n","implementation\n","taking\n","decreases\n","applying\n","iterative\n","czech\n","steps\n","bnc\n","wilks\n","closely\n","reports\n","performs\n","moens\n","wong\n","hiero\n","dataset\n","evaluating\n","lesk\n","benefit\n","drawn\n","recognizer\n","hypotheses\n","relationships\n","entities\n","required\n","trie\n","byte\n","bits\n","emphasize\n","liddy\n","close\n","mst\n","units\n","follow\n","primarily\n","database\n","hirst\n","reasoning\n","opinions\n","taken\n","numbers\n","guthrie\n","handcrafted\n","national\n","variables\n","sampler\n","samplers\n","via\n","explicitly\n","tries\n","sources\n","strongly\n","priori\n","mapping\n","true\n","crf\n","chunking\n","fano\n","above\n","run\n","integrated\n","considering\n","bangalore\n","joshi\n","baldwin\n","vb\n","amounts\n","provided\n","ln\n","svm\n","notion\n","degree\n","built\n","lafferty\n","reducing\n","count\n","hasan\n","classifiers\n","mccallum\n","baldridge\n","divergence\n","referred\n","almost\n","estimator\n","least\n","concept\n","network\n","improving\n","school\n","approximations\n","specificity\n","contain\n","extra\n","aim\n","explores\n","single\n","extent\n","resolving\n","query\n","hearst\n","sparseness\n","overlap\n","fast\n","implemented\n","gold\n","necessarily\n","clustered\n","correct\n","ones\n","bound\n","corresponding\n","infinite\n","mainly\n","px\n","occurrences\n","cpu\n","node\n","back\n","generally\n","resource\n","exhaustive\n","documents\n","strategies\n","line\n","forward\n","yet\n","generates\n","prune\n","therefore\n","parts\n","watanabe\n","summaries\n","suggested\n","asymptotically\n","determinant\n","itai\n","level\n","acquired\n","neural\n","through\n","did\n","reasons\n","introduce\n","croft\n","assign\n","tagged\n","material\n","spanning\n","apple\n","tools\n","setup\n","monolingual\n","difference\n","vat\n","quat\n","british\n","ranked\n","constraint\n","constituent\n","zesch\n","fragments\n","before\n","sampson\n","de\n","gb\n","collected\n","empirical\n","concise\n","symbols\n","future\n","experiment\n","distinct\n","numerous\n","survey\n","near\n","phenomena\n","preferences\n","strongest\n","construct\n","segmentation\n","constrained\n","reach\n","paskin\n","increased\n","derivations\n","complex\n","discourse\n","inter\n","alia\n","limitations\n","exploited\n","intonation\n","annotations\n","indices\n","attempts\n","constructions\n","carroll\n","briscoe\n","kubler\n","ams\n","otherwise\n","distances\n","german\n","rich\n","bell\n","chodorow\n","assumption\n","traditional\n","ldv\n","consulted\n","roget\n","attributional\n","answering\n","path\n","kurihara\n","sato\n","election\n","ge\n","lu\n","extensions\n","style\n","lappin\n","kennedy\n","designed\n","bennett\n","employs\n","impact\n","upon\n","review\n","uniform\n","believe\n","als\n","must\n","ergodic\n","kuhn\n","el\n","specifically\n","separately\n","ca\n","penn\n","encode\n","ldc\n","block\n","encoding\n","randomized\n","equivalent\n","magnitude\n","enhanced\n","strings\n","paik\n","observations\n","pronouns\n","fj\n","underlying\n","predicted\n","billion\n","newswire\n","matching\n","brent\n","dorr\n","drawing\n","regularization\n","distinction\n","semantically\n","predictions\n","choosing\n","making\n","tradeoff\n","crafted\n","illustrative\n","lai\n","kneser\n","computer\n","science\n","taiwan\n","predict\n","salton\n","contains\n","mistakes\n","huge\n","involved\n","beam\n","equations\n","left\n","deleted\n","interpolation\n","refinement\n","broad\n","view\n","aspects\n","encyclopedias\n","representative\n","programs\n","items\n","sensitive\n","l\n","leave\n","factor\n","links\n","strength\n","analyze\n","matsumoto\n","reuters\n","observing\n","approximated\n","z\n","zy\n","guiliano\n","symmetric\n","noted\n","fields\n","tj\n","yielded\n","reference\n","apply\n","extended\n","normally\n","subject\n","head\n","shorter\n","modifying\n","represent\n","modifiers\n","moving\n","wn\n","variance\n","match\n","vo\n","ap\n","frameworks\n","summing\n","marginals\n","enforcing\n","nonterminal\n","threshold\n","partly\n","few\n","addressed\n","appropriate\n","details\n","perceptron\n","option\n","mcclosky\n","inducing\n","denis\n","remain\n","biased\n","indicated\n","unit\n","checked\n","lookup\n","rao\n","prime\n","ran\n","estimators\n","converge\n","subjects\n","exact\n","mapped\n","forming\n","templates\n","informatics\n","edinburgh\n","composed\n","call\n","positives\n","false\n","pasting\n","perplexity\n","adda\n","conjunction\n","shepherd\n","adaptations\n","mima\n","matches\n","ours\n","hat\n","listed\n","plus\n","morphemes\n","petrov\n","inherent\n","explains\n","removing\n","sekine\n","chang\n","prep\n","acquiring\n","elworthy\n","expansion\n","pang\n","index\n","ccg\n","carried\n","triple\n","transducers\n","million\n","exist\n","regression\n","discovery\n","parc\n","press\n","convergence\n","allowing\n","sampling\n","buckshot\n","looking\n","simmons\n","sometimes\n","get\n","tends\n","correctly\n","extracts\n","selects\n","versions\n","pyx\n","py\n","days\n","iteration\n","pc\n","deletion\n","giza\n","again\n","graphs\n","increasing\n","propagation\n","deterministic\n","short\n","artificial\n","product\n","earlier\n","adopted\n","decisions\n","driven\n","looks\n","atwell\n","lexicons\n","isolation\n","hits\n","filtering\n","adopt\n","trials\n","finding\n","paradigms\n","paradigmatic\n","cannot\n","original\n","aggregate\n","cluster\n","seems\n","rejoin\n","belong\n","returned\n","say\n","weighted\n","tens\n","millions\n","fewer\n","load\n","comparable\n","situation\n","become\n","sch\n","doing\n","revision\n","revising\n","inside\n","dominated\n","engineering\n","graphical\n","originally\n","discuss\n","typical\n","participants\n","decomposition\n","evaluate\n","cautious\n","regardless\n","sequential\n","adapted\n","discrimination\n","mdi\n","ne\n","kempe\n","itg\n","easily\n","modification\n","surprising\n","somewhat\n","opposed\n","body\n","comes\n","ending\n","towell\n","generalized\n","necessary\n","teacher\n","teachers\n","earliest\n","nevertheless\n","tokens\n","henceforth\n","gibbs\n","alignments\n","black\n","focused\n","refer\n","having\n","distinctions\n","practical\n","comparative\n","especially\n","tuning\n","operations\n","combining\n","substituting\n","limit\n","long\n","bagga\n","appears\n","subset\n","substitutes\n","expectation\n","occurrence\n","illustrated\n","bichat\n","brok\n","jok\n","lat\n","stok\n","cat\n","mok\n","gat\n","mat\n","incorporated\n","collection\n","relatively\n","chinese\n","towards\n","practically\n","r\n","bene\n","gj\n","chose\n","contribution\n","center\n","ax\n","cz\n","you\n","needs\n","accounted\n","pointed\n","calls\n","windows\n","firth\n","know\n","restrictions\n","noise\n","predominant\n","object\n","eat\n","raw\n","arcs\n","bod\n","postprocessing\n","performed\n","final\n","predictive\n","merging\n","null\n","regarded\n","mr\n","mmi\n","jv\n","informatica\n","universita\n","italy\n","prepositional\n","marciniak\n","depend\n","employ\n","ot\n","minimal\n","vary\n","paraphrasing\n","acquire\n","chunk\n","th\n","rough\n","thumb\n","rose\n","schwartz\n","neighboring\n","characteristics\n","bai\n","abstracting\n","dirt\n","titi\n","witi\n","us\n","toward\n","sparser\n","dirichlet\n","plan\n","amaya\n","cost\n","embedded\n","pms\n","remaining\n","jones\n","ned\n","enforce\n","ultimately\n","free\n","prepositions\n","proves\n","reassuring\n","isozaki\n","krishnan\n","overall\n","serve\n","predictors\n","detected\n","compress\n","interpreting\n","compounds\n","lauer\n","nal\n","gaining\n","popularity\n","morpheme\n","teh\n","whose\n","peak\n","wallstreet\n","journal\n","contingency\n","buchholz\n","marsi\n","reveals\n","move\n","attempt\n","phenomenon\n","standards\n","tobi\n","tones\n","break\n","silverman\n","targeting\n","effects\n","chance\n","population\n","petrovic\n","cover\n","denoted\n","incomplete\n","working\n","presentation\n","translating\n","spanish\n","morphology\n","morphologically\n","closer\n","look\n","sketch\n","engine\n","steier\n","belew\n","expressed\n","retrieved\n","rasp\n","wilson\n","subjective\n","omit\n","rise\n","invalid\n","unrealistic\n","placeholders\n","unique\n","wacholder\n","respect\n","resembles\n","restricted\n","strict\n","subclass\n","cells\n","summarize\n","wiki\n","surrounding\n","lowe\n","relevance\n","saul\n","targets\n","resolve\n","spoken\n","venugopal\n","marton\n","role\n","antecedent\n","governing\n","pronoun\n","guessers\n","endings\n","capitalization\n","approximate\n","varying\n","ideal\n","sr\n","advocated\n","limiting\n","connected\n","observation\n","reliability\n","limited\n","tight\n","morphosyntactic\n","translated\n","combined\n","facet\n","dakka\n","contained\n","wsj\n","bytes\n","files\n","delivered\n","compact\n","clarkson\n","ids\n","evaluates\n","mcmc\n","yielding\n","supported\n","founded\n","xi\n","young\n","filter\n","symmetrical\n","par\n","wsf\n","wtf\n","denote\n","measurement\n","synonym\n","submission\n","lattices\n","ideas\n","encodes\n","iob\n","focuses\n","xia\n","garman\n","weinberg\n","etal\n","confidence\n","renyi\n","argues\n","formulated\n","analogical\n","applies\n","verbal\n","gained\n","issues\n","faced\n","forecasting\n","observes\n","involves\n","qualities\n","everyday\n","cowie\n","department\n","tsing\n","hua\n","hsinchu\n","roc\n","handled\n","efficiency\n","bhattacharya\n","investigating\n","jain\n","neal\n","permutation\n","celebrated\n","citation\n","sebastiani\n","generalizes\n","harvesting\n","realize\n","mentioned\n","noisy\n","plenty\n","variability\n","genres\n","still\n","open\n","suet\n","easy\n","reliably\n","changing\n","sizes\n","yamashina\n","touch\n","feasibility\n","scope\n","chart\n","systematic\n","generalizable\n","meanings\n","accessible\n","readable\n","coupled\n","analytic\n","apparatus\n","needed\n","fruitfully\n","explore\n","cope\n","massive\n","borders\n","perceptual\n","experience\n","assume\n","resulting\n","differed\n","unclear\n","exploits\n","linked\n","retained\n","certain\n","conditions\n","u\n","prescribed\n","ptb\n","kudo\n","aug\n","dec\n","eqs\n","pr\n","gf\n","ferreira\n","paca\n","experimented\n","frame\n","similarly\n","particularly\n","lists\n","nielsen\n","leveraging\n","fossum\n","records\n","books\n","canisius\n","sporleder\n","michelson\n","knoblock\n","psd\n","serious\n","practice\n","ji\n","tfi\n","modifier\n","determiners\n","spearman\n","finkelstein\n","odp\n","cast\n","theoretic\n","french\n","fx\n","fy\n","meanwhile\n","acknowledgments\n","thank\n","my\n","fellow\n","organizers\n","johan\n","hall\n","sandra\n","ryan\n","jens\n","nilsson\n","sebastian\n","riedel\n","deniz\n","defect\n","selecting\n","draws\n","medical\n","carreras\n","specify\n","lbj\n","classified\n","relying\n","preexisting\n","taxonomies\n","alvarez\n","lim\n","powers\n","heilman\n","relied\n","soon\n","morton\n","kehler\n","andor\n","covers\n","unanswered\n","created\n","reader\n","characters\n","start\n","capitalized\n","developing\n","exploring\n","decades\n","randomly\n","jittered\n","carefully\n","extractive\n","antonym\n","dsn\n","course\n","mapreduce\n","psycholinguistics\n","testing\n","approximation\n","electronic\n","textual\n","haghighi\n","insist\n","elaborate\n","program\n","midrange\n","hieu\n","philipp\n","abstract\n","act\n","mozer\n","sensitivity\n","cr\n","negatives\n","indirectly\n","additionally\n","segments\n","supplied\n","ili\n","pwi\n","alternatively\n","characteristic\n","sibling\n","post\n","theories\n","bug\n","shimizu\n","nakagawa\n","inconclusive\n","effectiveness\n","scl\n","unexplored\n","yf\n","tmi\n","nested\n","pt\n","attested\n","lexile\n","chain\n","duan\n","tsujii\n","highest\n","track\n","turns\n","prevent\n","injection\n","cohen\n","np\n","arc\n","indicates\n","entry\n","microsoft\n","companies\n","nasdaq\n","cloud\n","vendors\n","description\n","lehman\n","merged\n","adjusted\n","pro\n","poses\n","derive\n","rence\n","summarizing\n","carter\n","triples\n","quadruples\n","binary\n","area\n","linguists\n","captured\n","fusion\n","chandrasekar\n","doran\n","cutoff\n","sash\n","point\n","relaxed\n","zc\n","nguyen\n","cao\n","gone\n","measuring\n","attempted\n","pearce\n","evert\n","shift\n","finite\n","formalisms\n","permitting\n","polynomial\n","ambiguities\n","jang\n","seven\n","longman\n","outputted\n","minimising\n","uno\n","moreover\n","aronson\n","extends\n","indicators\n","davidov\n","rappoport\n","references\n","xt\n","doug\n","julian\n","jan\n","penelope\n","manifestation\n","weld\n","ratios\n","wyner\n","nearly\n","formulates\n","factoring\n","until\n","neill\n","attracts\n","unassigned\n","predetermined\n","coherent\n","corruption\n","investigator\n","researcher\n","tile\n","debate\n","paid\n","shannons\n","redundant\n","printed\n","deliberately\n","misspelled\n","synthesizer\n","coyote\n","spelled\n","figures\n","confirms\n","subsequence\n","increase\n","dimensionality\n","complexity\n","concerns\n","blitzer\n","scenario\n","selected\n","constant\n","grow\n","indefinitely\n","arguments\n","purposes\n","growing\n","jacobs\n","event\n","align\n","anonymous\n","link\n","hours\n","realign\n","clearest\n","improves\n","depth\n","opposite\n","trend\n","suffer\n","originating\n","fragmented\n","blended\n","ifw\n","nativist\n","biases\n","innate\n","ellison\n","affinities\n","terra\n","diab\n","globally\n","optimized\n","searching\n","laso\n","heuristics\n","stolz\n","tannenbaum\n","carstensen\n","marshall\n","beale\n","nie\n","schafer\n","projections\n","hwa\n","collectively\n","keyword\n","relationship\n","wider\n","translate\n","stroppa\n","hubs\n","authorities\n","degraded\n","nearest\n","neighbours\n","token\n","constructing\n","analogies\n","put\n","last\n","adopting\n","terminology\n","keeping\n","hereby\n","regard\n","largely\n","classed\n","antonyms\n","invoke\n","said\n","ruger\n","compiled\n","clauses\n","conjoined\n","machines\n","queried\n","requests\n","predicates\n","join\n","quit\n","guide\n","induct\n","launch\n","participate\n","return\n","sign\n","meet\n","desirable\n","servers\n","heavily\n","corresponds\n","rest\n","golding\n","decide\n","wed\n","paradigm\n","extending\n","adaptor\n","adaptive\n","informative\n","optimizes\n","steedman\n","realization\n","white\n","dialog\n","beavers\n","priming\n","reitter\n","undirected\n","baum\n","sadler\n","maarek\n","completeness\n","popularized\n","avoided\n","aligners\n","union\n","conditioned\n","presence\n","ki\n","kx\n","multiplying\n","yields\n","desired\n","fader\n","objective\n","speakers\n","callan\n","nes\n","exploit\n","gather\n","collecting\n","broader\n","symbolic\n","constituents\n","inversion\n","versus\n","supports\n","nice\n","theoretical\n","fq\n","ffu\n","ffv\n","adequately\n","trigram\n","absolute\n","motivate\n","regularized\n","tle\n","psycholinguistic\n","landauer\n","usage\n","digital\n","reflecting\n","organisation\n","mental\n","mean\n","binomial\n","variational\n","implement\n","preserving\n","guarantees\n","snyder\n","multiplication\n","triangular\n","logarithm\n","raise\n","unified\n","findings\n","somehow\n","eventually\n","believed\n","tensor\n","aaaaa\n","methodologies\n","address\n","o\n","returns\n","sco\n","wj\n","cw\n","encouraging\n","rigid\n","syntax\n","combinators\n","telugu\n","bharati\n","ourselves\n","already\n","avoid\n","maximizing\n","marginalizing\n","sort\n","bottleneck\n","contrastive\n","please\n","dependent\n","builtin\n","guessing\n","schwall\n","edelman\n","walker\n","amsler\n","niwa\n","nitta\n","providing\n","burden\n","feedback\n","harman\n","buckley\n","xu\n","robertson\n","interpolated\n","smoothed\n","trigrams\n","backward\n","accomplished\n","former\n","speed\n","cube\n","mode\n","nagata\n","googles\n","traditionally\n","weblink\n","social\n","lewis\n","handbook\n","soldier\n","gun\n","fragment\n","handbooks\n","soldiers\n","guns\n","schools\n","cer\n","coded\n","worse\n","becomes\n","stc\n","interaction\n","proteins\n","bd\n","quantities\n","quote\n","fails\n","zd\n","cl\n","biomedical\n","wilbur\n","collapsed\n","exploitation\n","advanced\n","strictly\n","contiguous\n","translational\n","equivalences\n","rivaled\n","discounting\n","averaging\n","successful\n","aimed\n","trying\n","overcome\n","essen\n","approached\n","consists\n","elements\n","unweighted\n","ruleset\n","parameterization\n","something\n","biasing\n","seeking\n","confusion\n","ayan\n","topics\n","sport\n","education\n","cues\n","differentiating\n","mentions\n","michael\n","jordan\n","basketball\n","player\n","professor\n","development\n","unlikely\n","attracted\n","exclusively\n","reproduce\n","analyzed\n","identified\n","six\n","extraneous\n","transformation\n","paraphrases\n","descriptions\n","increasingly\n","consortium\n","disambiguated\n","namely\n","mention\n","detection\n","md\n","consistent\n","stemming\n","reproduced\n","mathematically\n","pfe\n","hi\n","simultaneously\n","directed\n","conceived\n","asymmetries\n","arise\n","fruit\n","importance\n","judgment\n","paths\n","exception\n","political\n","win\n","posted\n","message\n","board\n","quantify\n","stt\n","compares\n","ensures\n","validity\n","walks\n","logical\n","greedy\n","obvious\n","orders\n","biggest\n","smallest\n","slovene\n","scholz\n","yamada\n","lerman\n","assuming\n","once\n","twice\n","effort\n","integrate\n","correcting\n","students\n","asked\n","extractor\n","beal\n","ci\n","fv\n","gv\n","ifv\n","ow\n","maynard\n","schwenk\n","tense\n","gender\n","meme\n","sil\n","la\n","pas\n","methodology\n","assocation\n","bed\n","produced\n","vogel\n","define\n","formulas\n","pf\n","pe\n","iat\n","bat\n","forat\n","exercise\n","contemporary\n","ayuso\n","norm\n","inductive\n","fully\n","handwriting\n","atc\n","ccl\n","itri\n","databases\n","franz\n","computation\n","implementations\n","sri\n","toolkit\n","federico\n","portage\n","badr\n","besides\n","balanced\n","tune\n","rpc\n","interpreted\n","conclusion\n","shallow\n","phrasal\n","miller\n","sections\n","distinguishes\n","formal\n","going\n","underpinnings\n","doubly\n","nite\n","informed\n","birch\n","hassan\n","reformulation\n","shed\n","light\n","predictability\n","unix\n","command\n","user\n","enter\n","yoshida\n","davison\n","hirsch\n","keystrokes\n","device\n","pda\n","darragh\n","witten\n","translator\n","foreign\n","ssl\n","combines\n","pdi\n","baron\n","freedman\n","ps\n","talukdar\n","nadeau\n","congress\n","italian\n","intelligence\n","palermo\n","computers\n","watson\n","aquisition\n","frames\n","acl\n","vol\n","influence\n","neighbour\n","represented\n","assessments\n","productions\n","subcategory\n","eight\n","combinations\n","topically\n","caraballo\n","thelen\n","zx\n","central\n","segment\n","underlies\n","expression\n","adds\n","dealing\n","confronted\n","insufficient\n","robustness\n","adaptable\n","dissimilarity\n","skew\n","tendency\n","wash\n","smear\n","defocus\n","exhibited\n","scales\n","empiricist\n","summarized\n","famous\n","dictum\n","linguist\n","jr\n","shall\n","company\n","keeps\n","identifying\n","schulte\n","im\n","walde\n","abe\n","layered\n","creates\n","reorders\n","pq\n","approaching\n","agree\n","law\n","prominent\n","individual\n","dates\n","berger\n","multiclass\n","sharpen\n","substrings\n","exclude\n","infrequent\n","acquires\n","predominance\n","cellulose\n","publication\n","medium\n","writing\n","scientific\n","publishing\n","firm\n","physical\n","tanaka\n","magnini\n","positions\n","nearby\n","misses\n","sleep\n","sit\n","vast\n","convert\n","scalar\n","kl\n","challenge\n","failed\n","meaningful\n","gains\n","occurring\n","intuitions\n","centering\n","theory\n","grosz\n","morris\n","confirming\n","retrieve\n","mto\n","sa\n","wl\n","iwl\n","fw\n","poorer\n","absence\n","weak\n","supervision\n","encoded\n","specialized\n","implicit\n","accepted\n","shortening\n","fusing\n","jeopardizes\n","xiong\n","hard\n","simply\n","prohibits\n","violate\n","infrastructure\n","modifications\n","dening\n","ic\n","stable\n","contrasted\n","stories\n","typed\n","splitting\n","planning\n","aggregation\n","dimensional\n","svd\n","group\n","agglomeration\n","discusses\n","introducing\n","nondeterministic\n","mechanism\n","re\n","partitioned\n","ww\n","position\n","objects\n","professionally\n","abstracts\n","operation\n","rooted\n","forest\n","computations\n","partially\n","removed\n","notice\n","bounded\n","mcarthur\n","mei\n","icsi\n","meeting\n","switchboard\n","eval\n","ppl\n","whittaker\n","woodland\n","ts\n","abounds\n","reverse\n","giuseppe\n","felice\n","closeness\n","dasgupta\n","deeper\n","constituency\n","largescale\n","tokunaga\n","emphasis\n","components\n","widespread\n","availability\n","own\n","na\n","sup\n","pavel\n","deese\n","conduct\n","analyses\n","measurements\n","convictions\n","evoke\n","reminiscent\n","detect\n","regularities\n","support\n","idioms\n","kick\n","bucket\n","aer\n","karlsson\n","anttila\n","till\n","writers\n","subjectivity\n","jindal\n","ravin\n","structural\n","jenson\n","delimiters\n","trellis\n","soong\n","luang\n","coordination\n","recognizing\n","proposes\n","grosser\n","banko\n","zhou\n","offered\n","schiffman\n","regeneration\n","challange\n","finch\n","rijsbergen\n","willett\n","effectively\n","reasonable\n","fishers\n","seed\n","recognised\n","service\n","reliable\n","trusted\n","classify\n","degrades\n","rapidly\n","investigated\n","enhancing\n","coherence\n","ontologies\n","ass\n","iverson\n","fass\n","kinds\n","jos\n","ilp\n","remove\n","redundancy\n","recursive\n","dp\n","treated\n","marginalized\n","suggestions\n","lexicographer\n","dundee\n","todman\n","alm\n","volume\n","greetings\n","narratives\n","beneficial\n","aac\n","formally\n","littman\n","orientation\n","tis\n","tjs\n","polar\n","prototypical\n","template\n","recourse\n","identical\n","lesser\n","dutch\n","heylen\n","initialize\n","emission\n","gives\n","indirect\n","affects\n","cf\n","flat\n","motivated\n","nontrivial\n","basic\n","subtree\n","investigate\n","paraphrase\n","lsa\n","lack\n","arabic\n","compatible\n","sakhr\n","tokenization\n","optimizing\n","criterion\n","lus\n","isa\n","hierarchy\n","sum\n","kirchhoff\n","minus\n","row\n","column\n","relaxation\n","nonstandard\n","nastase\n","sumida\n","implies\n","codes\n","commitment\n","identifies\n","title\n","littered\n","transducer\n","away\n","separate\n","claws\n","importantly\n","facilitates\n","incorporation\n","assigning\n","called\n","inflection\n","folding\n","end\n","sliding\n","sarkar\n","mathematical\n","understanding\n","follows\n","majority\n","belonging\n","decomposes\n","quite\n","helpful\n","styles\n","kuhlmann\n","mohl\n","hindi\n","flexible\n","generalisation\n","palo\n","alto\n","distortion\n","covered\n","ee\n","remedy\n","aggressively\n","fraction\n","reduces\n","predicting\n","aic\n","aicc\n","akaike\n","tsai\n","lebreton\n","mixture\n"]}]},{"cell_type":"code","source":["#tokenizer converts words in the sentence into its corresponding indexe \n","print(X_train.iloc[-1])  \n","print(tokenizer.texts_to_sequences(X_train)[-1])\n","print('the word since, the first word of the last sentence in the dataset has index: ', words_to_index['regardless'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836037026,"user_tz":240,"elapsed":144,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"650bbb94-c078-4426-8a4e-cfdf4d443561","id":"2D90bAcAILNE"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["We used pointwise mutual information PMI Church and Hanks  to obtain these distances\n","[19, 18, 133, 45, 21, 514, 17, 1, 27, 7, 1276, 94, 1697]\n","the word since, the first word of the last sentence in the dataset has index:  2026\n"]}]},{"cell_type":"code","source":["#convert training data sentence words into its corresponding indexes\n","X_train_indices = tokenizer.texts_to_sequences(X_train)\n","\n","#pad sentences of indexes so all same length\n","X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n","print('the shape of the new training data is 796 samples, each with 835 words (bc of padding): ', X_train_indices.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836037235,"user_tz":240,"elapsed":213,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"edc18503-ada6-45d9-8ddb-d94abd6872e4","id":"HvAfR1D5ILNE"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["the shape of the new training data is 796 samples, each with 835 words (bc of padding):  (2150, 969)\n"]}]},{"cell_type":"markdown","source":["## Train Model"],"metadata":{"id":"3BM7XhbpGIvj"}},{"cell_type":"code","source":["# create model architecture\n","def imdb_rating(input_shape):\n","\n","  X_indices = Input(input_shape)\n","\n","  embeddings = embedding_layer(X_indices)\n","\n","  X = LSTM(128, return_sequences=True)(embeddings)\n","\n","  X = Dropout(0.6)(X)\n","\n","  X = LSTM(128, return_sequences=True)(X)\n","\n","  X = Dropout(0.6)(X)\n","\n","  X = LSTM(128)(X)\n","\n","  #X = Dense(1, activation='sigmoid')(X)\n","\n","  X = Dense(3, activation='softmax')(X)\n","\n","  model = Model(inputs=X_indices, outputs=X)\n","\n","  return model"],"metadata":{"id":"JDA-0ehuILND","executionInfo":{"status":"ok","timestamp":1650836037236,"user_tz":240,"elapsed":7,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["#train the model\n","model = imdb_rating((maxLen,))\n","\n","model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train_indices, Y_train, batch_size=256, epochs=15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836153342,"user_tz":240,"elapsed":116111,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"fe82c132-f652-4593-a88b-3daf4834bc4e","id":"-RBRdqh-ILNE"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","9/9 [==============================] - 17s 739ms/step - loss: 0.6751 - accuracy: 0.3442\n","Epoch 2/15\n","9/9 [==============================] - 7s 732ms/step - loss: 0.6460 - accuracy: 0.3265\n","Epoch 3/15\n","9/9 [==============================] - 7s 734ms/step - loss: 0.6390 - accuracy: 0.3340\n","Epoch 4/15\n","9/9 [==============================] - 7s 732ms/step - loss: 0.6381 - accuracy: 0.3442\n","Epoch 5/15\n","9/9 [==============================] - 7s 738ms/step - loss: 0.6370 - accuracy: 0.3405\n","Epoch 6/15\n","9/9 [==============================] - 7s 734ms/step - loss: 0.6366 - accuracy: 0.3433\n","Epoch 7/15\n","9/9 [==============================] - 7s 733ms/step - loss: 0.6367 - accuracy: 0.3442\n","Epoch 8/15\n","9/9 [==============================] - 7s 736ms/step - loss: 0.6367 - accuracy: 0.3456\n","Epoch 9/15\n","9/9 [==============================] - 7s 745ms/step - loss: 0.6362 - accuracy: 0.3353\n","Epoch 10/15\n","9/9 [==============================] - 7s 747ms/step - loss: 0.6368 - accuracy: 0.3395\n","Epoch 11/15\n","9/9 [==============================] - 7s 736ms/step - loss: 0.6369 - accuracy: 0.3372\n","Epoch 12/15\n","9/9 [==============================] - 7s 745ms/step - loss: 0.6365 - accuracy: 0.3442\n","Epoch 13/15\n","9/9 [==============================] - 7s 735ms/step - loss: 0.6365 - accuracy: 0.3581\n","Epoch 14/15\n","9/9 [==============================] - 7s 738ms/step - loss: 0.6371 - accuracy: 0.3367\n","Epoch 15/15\n","9/9 [==============================] - 7s 737ms/step - loss: 0.6364 - accuracy: 0.3437\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff045a93890>"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["## Test Model"],"metadata":{"id":"8J6Nsak3GtzJ"}},{"cell_type":"code","source":["#convert the testing data sentence words into its corresponding indexes\n","X_test_indices = tokenizer.texts_to_sequences(X_test)\n","\n","#pad sentences of indexes so all same length\n","X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n","print('the shape of the new training data is 200 samples, each with 835 words (bc of padding): ', X_test_indices.shape)\n","\n","\n","model.evaluate(X_test_indices, Y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836160341,"user_tz":240,"elapsed":7008,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"adfa36d3-320a-4b14-e655-58808c1adb0b","id":"IP_I7Z2xILNF"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["the shape of the new training data is 200 samples, each with 835 words (bc of padding):  (538, 969)\n","17/17 [==============================] - 4s 150ms/step - loss: 0.6388 - accuracy: 0.2900\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6387765407562256, 0.2899628281593323]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["my_predictions = model.predict(X_test_indices)"],"metadata":{"id":"lB2oQULqILNF","executionInfo":{"status":"ok","timestamp":1650836164033,"user_tz":240,"elapsed":3698,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["my_predictions[:100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836164035,"user_tz":240,"elapsed":34,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"f4e945b6-266d-4dfd-a992-73def523e888","id":"7xpVE26aILNF"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.36535794, 0.32392806, 0.31071407],\n","       [0.36535788, 0.3239281 , 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392806, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392806, 0.31071404],\n","       [0.36535788, 0.3239281 , 0.31071407],\n","       [0.36535788, 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535794, 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535794, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535794, 0.32392803, 0.31071407],\n","       [0.36535788, 0.3239281 , 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535794, 0.32392806, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392806, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.3239281 , 0.31071407],\n","       [0.3653579 , 0.32392803, 0.3107141 ],\n","       [0.3653579 , 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.3239281 , 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535794, 0.32392806, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535794, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.3107141 ],\n","       [0.3653579 , 0.32392806, 0.31071404],\n","       [0.36535788, 0.3239281 , 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392806, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.3107141 ],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.3239281 , 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.3239281 , 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.32392806, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535794, 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.3107141 ],\n","       [0.36535788, 0.32392803, 0.31071404],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.36535794, 0.32392806, 0.31071407],\n","       [0.36535788, 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392803, 0.31071407],\n","       [0.3653579 , 0.32392806, 0.31071404]], dtype=float32)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["#take max of the softmax output\n","my_predictions_final = np.argmax(my_predictions, axis=1)\n","\n","#map values back to (-1,0,1)\n","my_predictions_final - 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sx0PvSoZJZYU","executionInfo":{"status":"ok","timestamp":1650836164035,"user_tz":240,"elapsed":21,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"149258d8-9336-489a-bcc3-f4de06b4b665"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["np.argmax(Y_test, axis=1)"],"metadata":{"id":"Vg15f33LJ6L8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650836164036,"user_tz":240,"elapsed":19,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"51dae582-c433-405c-ceaa-bf362c0de13a"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 2, 2,\n","       1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2,\n","       1, 1, 0, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0,\n","       1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 2, 0, 1,\n","       0, 0, 2, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 1,\n","       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 0, 1, 2, 1, 1, 1,\n","       0, 2, 2, 1, 2, 1, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 1, 0, 1, 2, 0, 1,\n","       1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 1, 0, 0,\n","       0, 2, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 2, 0, 1, 2,\n","       1, 0, 0, 2, 2, 2, 2, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0,\n","       2, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1,\n","       1, 2, 1, 1, 2, 2, 2, 2, 1, 0, 2, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 0,\n","       2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2, 2, 1, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 2, 0, 1, 1, 0, 1,\n","       1, 2, 0, 0, 2, 1, 0, 1, 0, 1, 0, 1, 2, 2, 2, 0, 1, 1, 2, 2, 1, 1,\n","       0, 2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 1,\n","       0, 2, 1, 1, 0, 0, 0, 2, 1, 2, 1, 1, 2, 1, 1, 0, 2, 1, 0, 0, 1, 0,\n","       1, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0,\n","       2, 0, 2, 1, 0, 2, 1, 0, 0, 1, 1, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 1,\n","       2, 1, 1, 2, 1, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 1, 0, 0,\n","       0, 2, 2, 0, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2,\n","       0, 2, 0, 1, 2, 0, 2, 0, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2, 0, 2, 2, 1,\n","       1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0,\n","       1, 0, 0, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 0, 1, 2, 2,\n","       1, 1, 0, 1, 0, 1, 2, 1, 1, 1])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[""],"metadata":{"id":"Dh36MIqwAa1u","executionInfo":{"status":"ok","timestamp":1650836164037,"user_tz":240,"elapsed":18,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"R0LVhkQJAas9","executionInfo":{"status":"ok","timestamp":1650836164128,"user_tz":240,"elapsed":108,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["#test random sentence that is definitely positive\n","test_sentence = \"I really love this paper because it is amazing\"\n","\n","#convert the testing data sentence words into its corresponding indexes\n","test_sentence_indices = tokenizer.texts_to_sequences(test_sentence)\n","\n","#pad sentences of indexes so all same length\n","test_sentence_indices = pad_sequences(test_sentence_indices, maxlen=maxLen, padding='post')\n","\n","model.predict(test_sentence_indices)\n","test_sentence_indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qI7R5OUQAECt","executionInfo":{"status":"ok","timestamp":1650836164579,"user_tz":240,"elapsed":454,"user":{"displayName":"sahar farajun","userId":"08766982238663737774"}},"outputId":"c543e08a-71e7-4da7-e7af-55ba9b969cf3"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 560,    0,    0, ...,    0,    0,    0],\n","       [   0,    0,    0, ...,    0,    0,    0],\n","       [2105,    0,    0, ...,    0,    0,    0],\n","       ...,\n","       [ 560,    0,    0, ...,    0,    0,    0],\n","       [ 658,    0,    0, ...,    0,    0,    0],\n","       [1279,    0,    0, ...,    0,    0,    0]], dtype=int32)"]},"metadata":{},"execution_count":37}]}]}